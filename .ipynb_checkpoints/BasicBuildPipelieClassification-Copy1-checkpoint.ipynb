{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "535c32aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import azureml.core\n",
    "from azureml.core import Workspace, Experiment, Datastore, Environment, Dataset\n",
    "from azureml.core.authentication import ServicePrincipalAuthentication\n",
    "from azureml.core import Workspace, Experiment, Datastore, Environment, Dataset\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute, DataFactoryCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\n",
    "from azureml.pipeline.core import Pipeline, PipelineParameter, PipelineData\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "from azureml.pipeline.core import PipelineParameter, PipelineData\n",
    "from azureml.data.output_dataset_config import OutputTabularDatasetConfig, OutputDatasetConfig, OutputFileDatasetConfig\n",
    "from azureml.data.datapath import DataPath\n",
    "from azureml.data.data_reference import DataReference\n",
    "from azureml.data.sql_data_reference import SqlDataReference\n",
    "from azureml.pipeline.steps import DataTransferStep\n",
    "import logging\n",
    "from azureml.core.model import Model\n",
    "from azureml.exceptions import WebserviceException\n",
    "import os, shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4e75d2",
   "metadata": {},
   "source": [
    "## Setting up Key Vault Values - Do not keep these around - run 1 time only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "1466b92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import azureml.core\n",
    "# import os, shutil\n",
    "# from azureml.core import Workspace, Experiment, Datastore, Environment, Dataset\n",
    "# from azureml.core.authentication import ServicePrincipalAuthentication\n",
    "\n",
    "# os.environ.setdefault('tenantId', 'XXXX')\n",
    "# os.environ.setdefault('servicePrincipalId', 'XXXX')\n",
    "# os.environ.setdefault('servicePrincipalPassword', 'XXXXXX')\n",
    "# os.environ.setdefault('wsName', 'XXX')\n",
    "# os.environ.setdefault('subscriptionId', 'XXXXX')\n",
    "# os.environ.setdefault('resourceGroup', 'XXXXX')\n",
    "\n",
    "\n",
    "# environment_variables = ['tenantId', 'servicePrincipalId', 'servicePrincipalPassword', 'wsName', \n",
    "#                          'subscriptionId', 'resourceGroup']\n",
    "\n",
    "# envs = {}\n",
    "\n",
    "# for x in environment_variables:\n",
    "#     print(x, \"=\", os.environ.get(x))\n",
    "#     envs[x] = os.environ.get(x)\n",
    "\n",
    "\n",
    "# sp = ServicePrincipalAuthentication(tenant_id=envs['tenantId'], # tenantID\n",
    "#                                     service_principal_id=envs['servicePrincipalId'], # clientId\n",
    "#                                     service_principal_password=envs['servicePrincipalPassword']) # clientSecret\n",
    "\n",
    "# ws = Workspace.get(name=envs['wsName'],\n",
    "#                    auth=sp,\n",
    "#                    subscription_id=envs['subscriptionId'],\n",
    "#                    resource_group=envs['resourceGroup'])\n",
    "# ws.get_details()\n",
    "# keyvault = ws.get_default_keyvault()\n",
    "\n",
    "# for x in environment_variables:\n",
    "#     print(x, \"=\", os.environ.get(x))\n",
    "#     keyvault.set_secret(name = x, value = envs[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "eb88252c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.48.0 to work with aml-dev\n",
      "Run By Notebook:False\n"
     ]
    }
   ],
   "source": [
    "def get_environment_variables():\n",
    "    global envs\n",
    "    global run_by_notebook \n",
    "    run_by_notebook = False\n",
    "    environment_variables = ['tenantId', 'servicePrincipalId', 'servicePrincipalPassword', 'wsName', \n",
    "                         'subscriptionId', 'resourceGroup']\n",
    "    envs = {}\n",
    "    for x in environment_variables:\n",
    "        if os.environ.get(x) == None:\n",
    "            #get the values from keyvault\n",
    "            run_by_notebook = True\n",
    "            print('retrieve from key vault, value is None: ' + x)\n",
    "            ws = Workspace.from_config()\n",
    "            keyvault = ws.get_default_keyvault()\n",
    "            kv_results = keyvault.get_secrets(environment_variables)\n",
    "            envs = kv_results\n",
    "            for x in envs:\n",
    "                os.environ.setdefault(x, envs[x])\n",
    "            exit\n",
    "        else:\n",
    "            envs[x] = os.environ.get(x)\n",
    "    return run_by_notebook\n",
    "\n",
    "\n",
    "\n",
    "get_environment_variables()\n",
    "sp = ServicePrincipalAuthentication(tenant_id=envs['tenantId'], # tenantID\n",
    "                                    service_principal_id=envs['servicePrincipalId'], # clientId\n",
    "                                    service_principal_password=envs['servicePrincipalPassword']) # clientSecret\n",
    "ws = Workspace.get(name=envs['wsName'],\n",
    "                       auth=sp,\n",
    "                       subscription_id=envs['subscriptionId'],\n",
    "                       resource_group=envs['resourceGroup'])\n",
    "ws.get_details()\n",
    "\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))\n",
    "print('Run By Notebook:' + str(run_by_notebook))\n",
    "# Get the default datastore\n",
    "default_ds = ws.get_default_datastore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "b578401e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_name = 'aml-cluster001'\n",
    "model_name_to_register = 'text_classification_001'\n",
    "experiment_folder = 'text_classificatin_example'\n",
    "conda_yml_file = 'textclassification_env.yml'\n",
    "registered_env_name = \"text-classificiation-env\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "8c502e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Select AML Compute Cluster\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "\n",
    "try:\n",
    "    # Check for existing compute target\n",
    "    pipeline_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # If it doesn't already exist, create it\n",
    "    try:\n",
    "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
    "        pipeline_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "        pipeline_cluster.wait_for_completion(show_output=True)\n",
    "    except Exception as ex:\n",
    "        print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "26731050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inital_model_version = 4\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    initial_model = Model(ws, model_name)\n",
    "    inital_model_version = initial_model.version\n",
    "except WebserviceException :\n",
    "    inital_model_version = 0\n",
    "print('inital_model_version = ' + str(inital_model_version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "ffd71ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_classificatin_example\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "# Create a folder for the pipeline step files\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "\n",
    "print(experiment_folder)\n",
    "\n",
    "run_path = './run_outputs'\n",
    "try:\n",
    "    shutil.rmtree(run_path)\n",
    "except:\n",
    "    print('continue run_outputs directory does not exits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "51e07df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"assetId\": \"azureml://locations/eastus2/workspaces/9634b616-29cb-4345-ae22-4be4e4bfe009/environments/text-classificiation-env/versions/1\",\n",
       "    \"databricks\": {\n",
       "        \"eggLibraries\": [],\n",
       "        \"jarLibraries\": [],\n",
       "        \"mavenLibraries\": [],\n",
       "        \"pypiLibraries\": [],\n",
       "        \"rcranLibraries\": []\n",
       "    },\n",
       "    \"docker\": {\n",
       "        \"arguments\": [],\n",
       "        \"baseDockerfile\": null,\n",
       "        \"baseImage\": \"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20221101.v1\",\n",
       "        \"baseImageRegistry\": {\n",
       "            \"address\": null,\n",
       "            \"password\": null,\n",
       "            \"registryIdentity\": null,\n",
       "            \"username\": null\n",
       "        },\n",
       "        \"buildContext\": null,\n",
       "        \"enabled\": false,\n",
       "        \"platform\": {\n",
       "            \"architecture\": \"amd64\",\n",
       "            \"os\": \"Linux\"\n",
       "        },\n",
       "        \"sharedVolumes\": true,\n",
       "        \"shmSize\": null\n",
       "    },\n",
       "    \"environmentVariables\": {\n",
       "        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n",
       "    },\n",
       "    \"inferencingStackVersion\": null,\n",
       "    \"name\": \"text-classificiation-env\",\n",
       "    \"python\": {\n",
       "        \"baseCondaEnvironment\": null,\n",
       "        \"condaDependencies\": {\n",
       "            \"dependencies\": [\n",
       "                \"python=3.8.5\",\n",
       "                \"scikit-learn\",\n",
       "                \"ipykernel\",\n",
       "                \"matplotlib\",\n",
       "                \"pandas\",\n",
       "                \"pip\",\n",
       "                {\n",
       "                    \"pip\": [\n",
       "                        \"azureml-defaults\",\n",
       "                        \"numpy\",\n",
       "                        \"joblib\",\n",
       "                        \"sklearn\"\n",
       "                    ]\n",
       "                }\n",
       "            ],\n",
       "            \"name\": \"textclassification_env\"\n",
       "        },\n",
       "        \"condaDependenciesFile\": null,\n",
       "        \"interpreterPath\": \"python\",\n",
       "        \"userManagedDependencies\": false\n",
       "    },\n",
       "    \"r\": null,\n",
       "    \"spark\": {\n",
       "        \"packages\": [],\n",
       "        \"precachePackages\": true,\n",
       "        \"repositories\": []\n",
       "    },\n",
       "    \"version\": \"1\"\n",
       "}"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = Environment.from_conda_specification(registered_env_name, conda_yml_file)\n",
    "env.register(workspace=ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "c3ed7db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run configuration created.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    registered_env = Environment.get(ws, registered_env_name)\n",
    "    pipeline_run_config = RunConfiguration()\n",
    "    \n",
    "    # Use the compute you created above. \n",
    "    pipeline_run_config.target = pipeline_cluster\n",
    "\n",
    "    # Assign the environment to the run configuration\n",
    "    pipeline_run_config.environment = registered_env\n",
    "    print (\"Run configuration created.\")\n",
    "except Exception as e: \n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9811f05d",
   "metadata": {},
   "source": [
    "## Define Output datasets\n",
    "\n",
    "The OutputFileDatasetConfig object is a special kind of data reference that is used for interim storage locations that can be passed between pipeline steps, so you'll create one and use at as the output for the first step and the input for the second step. Note that you need to pass it as a script argument so your code can access the datastore location referenced by the data reference.\n",
    "\n",
    "Note, in all cases we specify the datastore that should hold the datasets and whether they should be registered following step completion or not. This can optionally be disabled by removing the register_on_complete() call.\n",
    "\n",
    "These can be viewed in the Datasets tab directly in the AML Portal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "3111d211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'text_classification_001'"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name_to_register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "1006ffbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data  = OutputFileDatasetConfig(name='training_data', destination=(default_ds, model_name_to_register + '_training_data/{run-id}')).read_delimited_files().register_on_complete(name= model_name_to_register + '_training_data')\n",
    "testing_data   = OutputFileDatasetConfig(name='testing_data',  destination=(default_ds, model_name_to_register +  '_testing_data/{run-id}')).read_delimited_files().register_on_complete(name= model_name_to_register + '_testing_data')\n",
    "\n",
    "model_file     = PipelineData(name='model_file', datastore=default_ds)\n",
    "\n",
    "model_name         = PipelineParameter(\"model_name\", default_value= model_name_to_register)\n",
    "model_desc         = PipelineParameter(\"model_desc\", default_value=model_name_to_register + ' description')\n",
    "raw_file_location  = PipelineParameter(name=\"raw_file_location\", default_value='spam-data/spamformodel.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae2c4bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "26038b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting text_classificatin_example/classifier_training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/classifier_training.py\n",
    "\n",
    "import argparse\n",
    "from azureml.core import Run, Workspace, Datastore, Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "\n",
    "def summarize_classification(y_test, y_pred, run):\n",
    "    acc = accuracy_score(y_test, y_pred, normalize=True) #how many predictions correct %\n",
    "    num_acc = accuracy_score(y_test, y_pred, normalize = False)\n",
    "    prec = precision_score(y_test, y_pred, average = 'weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    \n",
    "    run.log('total count', len(y_test))\n",
    "    run.log('acc count', num_acc)\n",
    "    run.log('Accuracy', acc)\n",
    "    run.log('prec', prec)\n",
    "    run.log('recall', recall)\n",
    "    \n",
    "    run.parent.log('acc count', num_acc)\n",
    "    run.parent.log('Accuracy', acc)\n",
    "    run.parent.log('prec', prec)\n",
    "    run.parent.log('recall', recall)\n",
    "\n",
    "\n",
    "    print('accuracy count:', num_acc)\n",
    "    print('accuracy score:', acc)\n",
    "    print('precision:', prec)\n",
    "    print('recall:', recall)\n",
    "    \n",
    "\n",
    "\n",
    "def getRuntimeArgs():\n",
    "    # Get script arguments\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--raw_file_location', dest='raw_file_location', required=True)\n",
    "    parser.add_argument('--training_data', dest='training_data', required=True)\n",
    "    parser.add_argument('--testing_data', dest='testing_data', required=True)\n",
    "    parser.add_argument('--model_file', dest='model_file', required=True)\n",
    "    parser.add_argument('--model_name', dest='model_name', required=True)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    return args\n",
    "\n",
    "def model_train(ds_df, run, training_data, testing_data):\n",
    "    \n",
    "    clf = Pipeline([\n",
    "                            ('count_vectorizer', CountVectorizer()),\n",
    "                            ('classifier', LogisticRegression(solver='lbfgs', max_iter=10000))\n",
    "                        ])\n",
    "    #output of convectorizer, feed to classifier\n",
    "    train, test = train_test_split(ds_df, test_size=0.2, random_state=0)\n",
    "\n",
    "    x_train = train['text']\n",
    "    y_train = train['labels']\n",
    "    \n",
    "    x_test = test['text']\n",
    "    y_test = test['labels']\n",
    "    \n",
    "    \n",
    "    print(train.head())\n",
    "\n",
    "\n",
    "    model = clf.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    \n",
    "    print('*************************')\n",
    "    print('model predictions:')\n",
    "    print(y_pred)\n",
    "    summarize_classification(y_test, y_pred, run)\n",
    "    \n",
    "    os.makedirs(training_data, exist_ok=True)\n",
    "    os.makedirs(testing_data, exist_ok=True)\n",
    "\n",
    "    test['results'] = y_pred\n",
    "    print('training_data = ' + training_data)\n",
    "    print('testing_data = ' + testing_data)\n",
    "    train.to_csv(os.path.join(training_data, 'training_data.csv'), index=False )\n",
    "    test.to_csv(os.path.join(testing_data, 'testing_data.csv'), index=False)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    args = getRuntimeArgs()\n",
    "    \n",
    "    raw_file_location = args.raw_file_location\n",
    "    training_data = args.training_data\n",
    "    testing_data = args.testing_data\n",
    "    model_file = args.model_file\n",
    "    model_name = args.model_name\n",
    "    \n",
    "    print(\"training_data =\" + training_data)\n",
    "    print('testing_data =' + testing_data)\n",
    "    # Get the experiment run context\n",
    "    run = Run.get_context()\n",
    "    ws = run.experiment.workspace\n",
    "    print(ws)\n",
    "    ds = ws.get_default_datastore()\n",
    "    \n",
    "    \n",
    "    print(\"Loading Data...\")\n",
    "    dataset = Dataset.Tabular.from_delimited_files(path = [(ds, raw_file_location)])\n",
    "    data = dataset.to_pandas_dataframe()\n",
    "    \n",
    "    \n",
    "    print(data.columns)\n",
    "    lr = model_train(data, run, training_data,  testing_data)\n",
    "    \n",
    "    os.makedirs('./outputs', exist_ok=True)\n",
    "    model_file_name = model_name  + '.pkl'\n",
    "    file_name = './outputs/' +model_file_name\n",
    "    \n",
    "    print(\"Joblib Version : \", joblib.__version__)\n",
    "    \n",
    "    joblib.dump(value=lr, filename=file_name)\n",
    "\n",
    "    #copy to pass model to next step as the model file\n",
    "    os.makedirs(model_file, exist_ok=True)\n",
    "    shutil.copyfile(file_name, os.path.join(model_file, model_file_name))\n",
    "\n",
    "    run.complete()\n",
    "\n",
    " \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ad4f74",
   "metadata": {},
   "source": [
    "## Train Model Python Script Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "911e98e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model_step = PythonScriptStep(\n",
    "    name='Get Data and Create Model',\n",
    "    script_name='classifier_training.py',\n",
    "    arguments =['--raw_file_location', raw_file_location,\n",
    "                '--training_data', training_data,\n",
    "                '--testing_data', testing_data,\n",
    "                '--model_file', model_file,\n",
    "                '--model_name', model_name\n",
    "               ],\n",
    "    inputs=[],\n",
    "    outputs=[model_file, training_data, testing_data],\n",
    "    compute_target=pipeline_cluster,\n",
    "    source_directory='./' + experiment_folder,\n",
    "    allow_reuse=False,\n",
    "    runconfig=pipeline_run_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28088b79",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "bd27090b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting text_classificatin_example/eval.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/eval.py\n",
    "\n",
    "from azureml.core import Run, Workspace, Datastore, Dataset\n",
    "from azureml.core.model import Model\n",
    "from azureml.data.datapath import DataPath\n",
    "\n",
    "import joblib\n",
    "import os\n",
    "import argparse\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.compute import ComputeTarget, AksCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.webservice import Webservice, AksWebservice\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(\"Evaluate model and register if more performant\")\n",
    "\n",
    "parser.add_argument('--model_name', dest='model_name', required=True)\n",
    "parser.add_argument('--model_file', dest = 'model_file',  required=True)\n",
    "parser.add_argument('--model_desc', dest = 'model_desc',  required=True)\n",
    "parser.add_argument('--deploy_file', dest='deploy_file', required=True)\n",
    "\n",
    "\n",
    "args, _ = parser.parse_known_args()\n",
    "model_name = args.model_name\n",
    "model_file = args.model_file\n",
    "model_desc = args.model_desc\n",
    "\n",
    "deploy_file = args.deploy_file\n",
    "\n",
    "#Get current run\n",
    "run = Run.get_context()\n",
    "\n",
    "#Get associated AML workspace\n",
    "ws = run.experiment.workspace\n",
    "\n",
    "#Get default datastore\n",
    "ds = ws.get_default_datastore()\n",
    "\n",
    "#Get metrics associated with current parent run\n",
    "metrics = run.get_metrics()\n",
    "\n",
    "print('current run metrics')\n",
    "for key in metrics.keys():\n",
    "        print(key, metrics.get(key))\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "print('parent run metrics')\n",
    "#Get metrics associated with current parent run\n",
    "metrics = run.parent.get_metrics()\n",
    "\n",
    "for key in metrics.keys():\n",
    "        print(key, metrics.get(key))\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "current_model_acc_count = float(metrics['acc count'])\n",
    "current_model_acc = float(metrics['Accuracy'])\n",
    "current_model_prec = float(metrics['prec'])\n",
    "current_model_recall = float(metrics['recall'])\n",
    "    \n",
    "\n",
    "# Get current model from workspace\n",
    "\n",
    "model_description = model_desc\n",
    "model_list = Model.list(ws, name=model_name, latest=True)\n",
    "first_registration = len(model_list)==0\n",
    "\n",
    "updated_tags = {'Accuracy': current_model_acc, 'prec': current_model_prec, 'recall': current_model_recall}\n",
    "\n",
    "\n",
    "print('updated tags')\n",
    "print(updated_tags)\n",
    "\n",
    "\n",
    "#upload model to the outputs directory\n",
    "relative_model_path = 'outputs'\n",
    "run.upload_folder(name=relative_model_path, path=model_file)\n",
    "\n",
    "model_file_name = model_name  + '.pkl'\n",
    "\n",
    "###################\n",
    "test_model = joblib.load(model_file + '/' + model_file_name)\n",
    "test_dataset = run.input_datasets['testing_data']\n",
    "df_test = test_dataset.to_pandas_dataframe()\n",
    "X = df_test['text']\n",
    "# Make predictions with new dataframe\n",
    "predictions = test_model.predict(X)\n",
    "print('predictions')\n",
    "print(predictions)\n",
    "#########################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#If no model exists register the current model\n",
    "if first_registration:\n",
    "    print('First model registration.')\n",
    "    model_reg = run.register_model(model_path='outputs/' + model_file_name, model_name=model_name,\n",
    "                   tags=updated_tags,\n",
    "                   properties=updated_tags)\n",
    "else:\n",
    "    #If a model has been registered previously, check to see if current model \n",
    "    #performs better. If so, register it.\n",
    "    print(dir(model_list[0]))\n",
    "    if float(model_list[0].tags['prec']) < current_model_prec:\n",
    "        print('New model performs better than existing model. Register it.')\n",
    "\n",
    "        model_reg = run.register_model(model_path='outputs/' + model_file_name, model_name=model_name,\n",
    "                   tags=updated_tags,\n",
    "                   properties=updated_tags)\n",
    "        \n",
    "        # Output accuracy to file\n",
    "        with open(deploy_file, 'w+') as f:\n",
    "            f.write(('deploy_model'))\n",
    "    \n",
    "    else:\n",
    "        print('New model does not perform better than existing model. Cancel run.')\n",
    "        \n",
    "        with open(deploy_file, 'w+') as f:\n",
    "            f.write(('do not deploy model'))\n",
    "            \n",
    "        run.complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "6a1bb502",
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_file = PipelineData(name='deploy_file', datastore=default_ds)\n",
    "\n",
    "evaluate_and_register_step = PythonScriptStep(\n",
    "    name='Evaluate and Register Model',\n",
    "    script_name='eval.py',\n",
    "    arguments=[\n",
    "        '--model_name', model_name,\n",
    "        '--model_file', model_file,\n",
    "        '--model_desc', model_desc,\n",
    "        '--deploy_file', deploy_file,       \n",
    "    ],\n",
    "    inputs=[model_file.as_input('model_file'),\n",
    "            training_data.as_input(name='training_data'),\n",
    "            testing_data.as_input(name='testing_data')\n",
    "           ],\n",
    "    outputs=[ deploy_file],\n",
    "    compute_target=pipeline_cluster,\n",
    "    source_directory='./' + experiment_folder,\n",
    "    allow_reuse=False,\n",
    "    runconfig=pipeline_run_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "892d148b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step Get Data and Create Model [dbab60f9][d7822985-5ff9-4921-87ad-6540da5a9be2], (This step will run and generate new outputs)\n",
      "Created step Evaluate and Register Model [0a8a0205][57c265b4-5e72-4e1f-9c0f-e103332f176d], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun 3913a927-924b-44f3-a119-abe8486aafea\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/3913a927-924b-44f3-a119-abe8486aafea?wsid=/subscriptions/b071bca8-0055-43f9-9ff8-ca9a144c2a6f/resourcegroups/aml-dev-rg/workspaces/aml-dev&tid=16b3c013-d300-468d-ac64-7eda0820b6d3\n",
      "PipelineRunId: 3913a927-924b-44f3-a119-abe8486aafea\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/3913a927-924b-44f3-a119-abe8486aafea?wsid=/subscriptions/b071bca8-0055-43f9-9ff8-ca9a144c2a6f/resourcegroups/aml-dev-rg/workspaces/aml-dev&tid=16b3c013-d300-468d-ac64-7eda0820b6d3\n",
      "PipelineRun Status: NotStarted\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: d5d6c6b4-a5d1-4797-8be2-8bc4ca6b09a1\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/d5d6c6b4-a5d1-4797-8be2-8bc4ca6b09a1?wsid=/subscriptions/b071bca8-0055-43f9-9ff8-ca9a144c2a6f/resourcegroups/aml-dev-rg/workspaces/aml-dev&tid=16b3c013-d300-468d-ac64-7eda0820b6d3\n",
      "StepRun( Get Data and Create Model ) Status: NotStarted\n",
      "StepRun( Get Data and Create Model ) Status: Running\n",
      "\n",
      "StepRun(Get Data and Create Model) Execution Summary\n",
      "=====================================================\n",
      "StepRun( Get Data and Create Model ) Status: Finished\n",
      "{'runId': 'd5d6c6b4-a5d1-4797-8be2-8bc4ca6b09a1', 'target': 'aml-cluster001', 'status': 'Completed', 'startTimeUtc': '2023-02-03T06:21:46.64075Z', 'endTimeUtc': '2023-02-03T06:22:15.824941Z', 'services': {}, 'properties': {'ContentSnapshotId': '4a9778b5-5d1e-426e-8f63-9f66137b3c91', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': 'd7822985-5ff9-4921-87ad-6540da5a9be2', 'azureml.moduleName': 'Get Data and Create Model', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': 'dbab60f9', 'azureml.pipelinerunid': '3913a927-924b-44f3-a119-abe8486aafea', 'azureml.pipeline': '3913a927-924b-44f3-a119-abe8486aafea', 'azureml.pipelineComponent': 'masterescloud', '_azureml.ComputeTargetType': 'amlctrain', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [], 'outputDatasets': [{'identifier': {'savedId': '724391cd-aedd-4c89-a749-8d27961e3c9d', 'registeredId': 'a1e4f36e-5abc-4647-b22f-b2190d0eb7db', 'registeredVersion': '8'}, 'outputType': 'RunOutput', 'outputDetails': {'outputName': 'training_data'}, 'dataset': {\n",
      "  \"source\": [\n",
      "    \"('workspaceblobstore', 'text_classification_001_training_data/d5d6c6b4-a5d1-4797-8be2-8bc4ca6b09a1')\"\n",
      "  ],\n",
      "  \"definition\": [\n",
      "    \"GetDatastoreFiles\",\n",
      "    \"ParseDelimited\",\n",
      "    \"DropColumns\"\n",
      "  ],\n",
      "  \"registration\": {\n",
      "    \"id\": \"724391cd-aedd-4c89-a749-8d27961e3c9d\",\n",
      "    \"name\": \"text_classification_001_training_data\",\n",
      "    \"version\": 8,\n",
      "    \"workspace\": \"Workspace.create(name='aml-dev', subscription_id='b071bca8-0055-43f9-9ff8-ca9a144c2a6f', resource_group='aml-dev-rg')\"\n",
      "  }\n",
      "}}, {'identifier': {'savedId': '28e9dfc4-8d60-4c28-b62e-4baaea8c3d54', 'registeredId': 'd38831ce-2192-4969-a808-aefdec11c14d', 'registeredVersion': '8'}, 'outputType': 'RunOutput', 'outputDetails': {'outputName': 'testing_data'}, 'dataset': {\n",
      "  \"source\": [\n",
      "    \"('workspaceblobstore', 'text_classification_001_testing_data/d5d6c6b4-a5d1-4797-8be2-8bc4ca6b09a1')\"\n",
      "  ],\n",
      "  \"definition\": [\n",
      "    \"GetDatastoreFiles\",\n",
      "    \"ParseDelimited\",\n",
      "    \"DropColumns\"\n",
      "  ],\n",
      "  \"registration\": {\n",
      "    \"id\": \"28e9dfc4-8d60-4c28-b62e-4baaea8c3d54\",\n",
      "    \"name\": \"text_classification_001_testing_data\",\n",
      "    \"version\": 8,\n",
      "    \"workspace\": \"Workspace.create(name='aml-dev', subscription_id='b071bca8-0055-43f9-9ff8-ca9a144c2a6f', resource_group='aml-dev-rg')\"\n",
      "  }\n",
      "}}], 'runDefinition': {'script': 'classifier_training.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--raw_file_location', '$AML_PARAMETER_raw_file_location', '--training_data', 'DatasetOutputConfig:training_data', '--testing_data', 'DatasetOutputConfig:testing_data', '--model_file', '$AZUREML_DATAREFERENCE_model_file', '--model_name', '$AML_PARAMETER_model_name'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'aml-cluster001', 'dataReferences': {'model_file': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/d5d6c6b4-a5d1-4797-8be2-8bc4ca6b09a1/model_file', 'pathOnCompute': None, 'overwrite': False}}, 'data': {}, 'outputData': {'training_data': {'outputLocation': {'dataset': None, 'dataPath': {'datastoreName': 'workspaceblobstore', 'relativePath': 'text_classification_001_training_data/{run-id}'}, 'uri': None, 'type': None}, 'mechanism': 'Mount', 'additionalOptions': {'pathOnCompute': None, 'registrationOptions': {'name': 'text_classification_001_training_data', 'description': None, 'tags': None, 'properties': {'azureml.pipelineRunId': '3913a927-924b-44f3-a119-abe8486aafea', 'azureml.pipelineRun.moduleNodeId': 'dbab60f9', 'azureml.pipelineRun.outputPortName': 'training_data'}, 'datasetRegistrationOptions': {'additionalTransformation': '{\\n  \"blocks\": [\\n    {\\n      \"id\": \"1f7fc7da-7ec3-4a59-8c2b-118e048aee58\",\\n      \"type\": \"Microsoft.DPrep.ParseDelimitedBlock\",\\n      \"arguments\": {\\n        \"columnHeadersMode\": 3,\\n        \"fileEncoding\": 0,\\n        \"handleQuotedLineBreaks\": false,\\n        \"preview\": false,\\n        \"separator\": \",\",\\n        \"skipRows\": 0,\\n        \"skipRowsMode\": 0\\n      },\\n      \"localData\": {},\\n      \"isEnabled\": true,\\n      \"name\": null,\\n      \"annotation\": null\\n    },\\n    {\\n      \"id\": \"0ee9526c-43fe-4953-903f-9e9facf6f313\",\\n      \"type\": \"Microsoft.DPrep.DropColumnsBlock\",\\n      \"arguments\": {\\n        \"columns\": {\\n          \"type\": 0,\\n          \"details\": {\\n            \"selectedColumns\": [\\n              \"Path\"\\n            ]\\n          }\\n        }\\n      },\\n      \"localData\": {},\\n      \"isEnabled\": true,\\n      \"name\": null,\\n      \"annotation\": null\\n    }\\n  ],\\n  \"inspectors\": [],\\n  \"meta\": {\\n    \"steps_added\": \"2\"\\n  }\\n}'}}, 'uploadOptions': {'overwrite': False, 'sourceGlobs': {'globPatterns': None}}, 'mountOptions': None}, 'environmentVariableName': None}, 'testing_data': {'outputLocation': {'dataset': None, 'dataPath': {'datastoreName': 'workspaceblobstore', 'relativePath': 'text_classification_001_testing_data/{run-id}'}, 'uri': None, 'type': None}, 'mechanism': 'Mount', 'additionalOptions': {'pathOnCompute': None, 'registrationOptions': {'name': 'text_classification_001_testing_data', 'description': None, 'tags': None, 'properties': {'azureml.pipelineRunId': '3913a927-924b-44f3-a119-abe8486aafea', 'azureml.pipelineRun.moduleNodeId': 'dbab60f9', 'azureml.pipelineRun.outputPortName': 'testing_data'}, 'datasetRegistrationOptions': {'additionalTransformation': '{\\n  \"blocks\": [\\n    {\\n      \"id\": \"3d5e40ae-bf66-4b87-83b5-aa1bdc69c06e\",\\n      \"type\": \"Microsoft.DPrep.ParseDelimitedBlock\",\\n      \"arguments\": {\\n        \"columnHeadersMode\": 3,\\n        \"fileEncoding\": 0,\\n        \"handleQuotedLineBreaks\": false,\\n        \"preview\": false,\\n        \"separator\": \",\",\\n        \"skipRows\": 0,\\n        \"skipRowsMode\": 0\\n      },\\n      \"localData\": {},\\n      \"isEnabled\": true,\\n      \"name\": null,\\n      \"annotation\": null\\n    },\\n    {\\n      \"id\": \"5711d0ab-c040-44d2-a5ba-95f1b8ccc2d1\",\\n      \"type\": \"Microsoft.DPrep.DropColumnsBlock\",\\n      \"arguments\": {\\n        \"columns\": {\\n          \"type\": 0,\\n          \"details\": {\\n            \"selectedColumns\": [\\n              \"Path\"\\n            ]\\n          }\\n        }\\n      },\\n      \"localData\": {},\\n      \"isEnabled\": true,\\n      \"name\": null,\\n      \"annotation\": null\\n    }\\n  ],\\n  \"inspectors\": [],\\n  \"meta\": {\\n    \"steps_added\": \"2\"\\n  }\\n}'}}, 'uploadOptions': {'overwrite': False, 'sourceGlobs': {'globPatterns': None}}, 'mountOptions': None}, 'environmentVariableName': None}}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'instanceTypes': [], 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'text-classificiation-env', 'version': '1', 'assetId': 'azureml://locations/eastus2/workspaces/9634b616-29cb-4345-ae22-4be4e4bfe009/environments/text-classificiation-env/versions/1', 'autoRebuild': True, 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'name': 'textclassification_env', 'dependencies': ['python=3.8.5', 'scikit-learn', 'ipykernel', 'matplotlib', 'pandas', 'pip', {'pip': ['azureml-defaults', 'numpy', 'joblib', 'sklearn']}]}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20221101.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': 'D2', 'imageVersion': 'pytorch-1.7.0', 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'sshPublicKeys': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard', 'userAlias': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {'AML_PARAMETER_raw_file_location': 'spam-data/spamformodel.csv', 'AML_PARAMETER_model_name': 'text_classification_001'}, 'applicationEndpoints': {}, 'parameters': []}, 'logFiles': {'logs/azureml/dataprep/0/backgroundProcess.log': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.d5d6c6b4-a5d1-4797-8be2-8bc4ca6b09a1/logs/azureml/dataprep/0/backgroundProcess.log?sv=2019-07-07&sr=b&sig=Ql2bQ%2FrYLHCrRafbkP24OZo4qTLFZ3iljPxTr2AMgyo%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-02T23%3A14%3A55Z&ske=2023-02-04T07%3A24%3A55Z&sks=b&skv=2019-07-07&st=2023-02-03T06%3A12%3A10Z&se=2023-02-03T14%3A22%3A10Z&sp=r', 'logs/azureml/dataprep/0/backgroundProcess_Telemetry.log': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.d5d6c6b4-a5d1-4797-8be2-8bc4ca6b09a1/logs/azureml/dataprep/0/backgroundProcess_Telemetry.log?sv=2019-07-07&sr=b&sig=ZxOIMv%2BBW2MWreZZtgUlhhEs7wW7mTzsgpbzSFZEI%2B8%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-02T23%3A14%3A55Z&ske=2023-02-04T07%3A24%3A55Z&sks=b&skv=2019-07-07&st=2023-02-03T06%3A12%3A10Z&se=2023-02-03T14%3A22%3A10Z&sp=r', 'logs/azureml/dataprep/0/rslex.log.2023-02-03-06': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.d5d6c6b4-a5d1-4797-8be2-8bc4ca6b09a1/logs/azureml/dataprep/0/rslex.log.2023-02-03-06?sv=2019-07-07&sr=b&sig=eMqBFnMJ2EOVq73aRDw2GgmmeFlwpgRJiIR%2BuNN2X1Q%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-02T23%3A14%3A55Z&ske=2023-02-04T07%3A24%3A55Z&sks=b&skv=2019-07-07&st=2023-02-03T06%3A12%3A10Z&se=2023-02-03T14%3A22%3A10Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.d5d6c6b4-a5d1-4797-8be2-8bc4ca6b09a1/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=GpSVxInFKIxLme1oRZT0YVCZ94O6m0lnz5ZaTOgu17w%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-02T23%3A14%3A55Z&ske=2023-02-04T07%3A24%3A55Z&sks=b&skv=2019-07-07&st=2023-02-03T06%3A12%3A10Z&se=2023-02-03T14%3A22%3A10Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.d5d6c6b4-a5d1-4797-8be2-8bc4ca6b09a1/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=qc2dIcSnfiGQEgmSw6v%2BiAu35%2F5cgEV0AtI1clXl4Go%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-02T23%3A14%3A55Z&ske=2023-02-04T07%3A24%3A55Z&sks=b&skv=2019-07-07&st=2023-02-03T06%3A12%3A10Z&se=2023-02-03T14%3A22%3A10Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.d5d6c6b4-a5d1-4797-8be2-8bc4ca6b09a1/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=TWBxhEtVrHOEwvzOCV4nP30HiQ4I519qMVHE%2BANT5UI%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-02T23%3A14%3A55Z&ske=2023-02-04T07%3A24%3A55Z&sks=b&skv=2019-07-07&st=2023-02-03T06%3A12%3A10Z&se=2023-02-03T14%3A22%3A10Z&sp=r', 'user_logs/std_log.txt': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.d5d6c6b4-a5d1-4797-8be2-8bc4ca6b09a1/user_logs/std_log.txt?sv=2019-07-07&sr=b&sig=OAZYy%2F0zf6Sy2gxs%2FlzGhzNjy17tE8lbRV6hLLFQXdk%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-02T23%3A14%3A55Z&ske=2023-02-04T07%3A24%3A55Z&sks=b&skv=2019-07-07&st=2023-02-03T06%3A12%3A17Z&se=2023-02-03T14%3A22%3A17Z&sp=r', 'system_logs/cs_capability/cs-capability.log': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.d5d6c6b4-a5d1-4797-8be2-8bc4ca6b09a1/system_logs/cs_capability/cs-capability.log?sv=2019-07-07&sr=b&sig=q3RMVbCYPdhA1JHuED3B1NY6ISgpZjDrO7MFmccBcTs%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-02T23%3A14%3A55Z&ske=2023-02-04T07%3A24%3A55Z&sks=b&skv=2019-07-07&st=2023-02-03T06%3A12%3A17Z&se=2023-02-03T14%3A22%3A17Z&sp=r', 'system_logs/data_capability/data-capability.log': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.d5d6c6b4-a5d1-4797-8be2-8bc4ca6b09a1/system_logs/data_capability/data-capability.log?sv=2019-07-07&sr=b&sig=TMxdON3%2FPbhFV5Rc0wx8Pq3j7xaCXD%2BeMvbJ0dZFELY%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-02T23%3A14%3A55Z&ske=2023-02-04T07%3A24%3A55Z&sks=b&skv=2019-07-07&st=2023-02-03T06%3A12%3A17Z&se=2023-02-03T14%3A22%3A17Z&sp=r', 'system_logs/data_capability/rslex.log.2023-02-03-06': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.d5d6c6b4-a5d1-4797-8be2-8bc4ca6b09a1/system_logs/data_capability/rslex.log.2023-02-03-06?sv=2019-07-07&sr=b&sig=yw1sPmDqP0930L%2FRcWVRJbWINgWeob%2BCgUw2AQKM%2BMU%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-02T23%3A14%3A55Z&ske=2023-02-04T07%3A24%3A55Z&sks=b&skv=2019-07-07&st=2023-02-03T06%3A12%3A17Z&se=2023-02-03T14%3A22%3A17Z&sp=r', 'system_logs/hosttools_capability/hosttools-capability.log': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.d5d6c6b4-a5d1-4797-8be2-8bc4ca6b09a1/system_logs/hosttools_capability/hosttools-capability.log?sv=2019-07-07&sr=b&sig=ViUnipg%2BaE0jrNtr2o%2BXRkyJcZXuFPtziPAkFtN6AvQ%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-02T23%3A14%3A55Z&ske=2023-02-04T07%3A24%3A55Z&sks=b&skv=2019-07-07&st=2023-02-03T06%3A12%3A17Z&se=2023-02-03T14%3A22%3A17Z&sp=r', 'system_logs/lifecycler/execution-wrapper.log': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.d5d6c6b4-a5d1-4797-8be2-8bc4ca6b09a1/system_logs/lifecycler/execution-wrapper.log?sv=2019-07-07&sr=b&sig=eapA44WFpG1I12EZzy8Z8%2FmpLMUWZWU9A%2F%2FH4sdYQ08%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-02T23%3A14%3A55Z&ske=2023-02-04T07%3A24%3A55Z&sks=b&skv=2019-07-07&st=2023-02-03T06%3A12%3A17Z&se=2023-02-03T14%3A22%3A17Z&sp=r', 'system_logs/lifecycler/lifecycler.log': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.d5d6c6b4-a5d1-4797-8be2-8bc4ca6b09a1/system_logs/lifecycler/lifecycler.log?sv=2019-07-07&sr=b&sig=KVOKAleg%2B1Eww1tAYlIpQwY8REi0D5T64Kq919L6fQk%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-02T23%3A14%3A55Z&ske=2023-02-04T07%3A24%3A55Z&sks=b&skv=2019-07-07&st=2023-02-03T06%3A12%3A17Z&se=2023-02-03T14%3A22%3A17Z&sp=r', 'system_logs/metrics_capability/metrics-capability.log': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.d5d6c6b4-a5d1-4797-8be2-8bc4ca6b09a1/system_logs/metrics_capability/metrics-capability.log?sv=2019-07-07&sr=b&sig=klVgN2%2BDxqHKE%2Bmi5hYgo3up1z5BfWNwYld1c3IJ4tA%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-02T23%3A14%3A55Z&ske=2023-02-04T07%3A24%3A55Z&sks=b&skv=2019-07-07&st=2023-02-03T06%3A12%3A17Z&se=2023-02-03T14%3A22%3A17Z&sp=r', 'system_logs/snapshot_capability/snapshot-capability.log': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.d5d6c6b4-a5d1-4797-8be2-8bc4ca6b09a1/system_logs/snapshot_capability/snapshot-capability.log?sv=2019-07-07&sr=b&sig=T%2B3iA5Tr%2BeJG90Oh3%2F34RW%2Fc3A96Lob6FX9nsFy66ic%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-02T23%3A14%3A55Z&ske=2023-02-04T07%3A24%3A55Z&sks=b&skv=2019-07-07&st=2023-02-03T06%3A12%3A17Z&se=2023-02-03T14%3A22%3A17Z&sp=r'}, 'submittedBy': 'e51aa7c8-2975-4062-85fe-af95c0b8e461'}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "StepRunId: 514c5a93-a903-4041-84dd-53e93ce5f861\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/514c5a93-a903-4041-84dd-53e93ce5f861?wsid=/subscriptions/b071bca8-0055-43f9-9ff8-ca9a144c2a6f/resourcegroups/aml-dev-rg/workspaces/aml-dev&tid=16b3c013-d300-468d-ac64-7eda0820b6d3\n",
      "StepRun( Evaluate and Register Model ) Status: NotStarted\n",
      "StepRun( Evaluate and Register Model ) Status: Running\n",
      "\n",
      "StepRun(Evaluate and Register Model) Execution Summary\n",
      "=======================================================\n",
      "StepRun( Evaluate and Register Model ) Status: Finished\n",
      "{'runId': '514c5a93-a903-4041-84dd-53e93ce5f861', 'target': 'aml-cluster001', 'status': 'Completed', 'startTimeUtc': '2023-02-03T06:22:23.988941Z', 'endTimeUtc': '2023-02-03T06:22:42.828589Z', 'services': {}, 'properties': {'ContentSnapshotId': '4a9778b5-5d1e-426e-8f63-9f66137b3c91', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '57c265b4-5e72-4e1f-9c0f-e103332f176d', 'azureml.moduleName': 'Evaluate and Register Model', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '0a8a0205', 'azureml.pipelinerunid': '3913a927-924b-44f3-a119-abe8486aafea', 'azureml.pipeline': '3913a927-924b-44f3-a119-abe8486aafea', 'azureml.pipelineComponent': 'masterescloud', '_azureml.ComputeTargetType': 'amlctrain', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [{'dataset': {'id': '2741583d-f789-4800-bb50-c4ef1e5ae150'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'training_data', 'mechanism': 'Direct'}}, {'dataset': {'id': '784c4dc8-1d2d-4839-a86f-b28d72f531c9'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'testing_data', 'mechanism': 'Direct'}}], 'outputDatasets': [], 'runDefinition': {'script': 'eval.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--model_name', '$AML_PARAMETER_model_name', '--model_file', '$AZUREML_DATAREFERENCE_model_file', '--model_desc', '$AML_PARAMETER_model_desc', '--deploy_file', '$AZUREML_DATAREFERENCE_deploy_file'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'aml-cluster001', 'dataReferences': {'model_file': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/d5d6c6b4-a5d1-4797-8be2-8bc4ca6b09a1/model_file', 'pathOnCompute': None, 'overwrite': False}, 'deploy_file': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/514c5a93-a903-4041-84dd-53e93ce5f861/deploy_file', 'pathOnCompute': None, 'overwrite': False}}, 'data': {'training_data': {'dataLocation': {'dataset': {'id': '2741583d-f789-4800-bb50-c4ef1e5ae150', 'name': None, 'version': None}, 'dataPath': None, 'uri': None, 'type': None}, 'mechanism': 'Direct', 'environmentVariableName': 'training_data', 'pathOnCompute': None, 'overwrite': False, 'options': None}, 'testing_data': {'dataLocation': {'dataset': {'id': '784c4dc8-1d2d-4839-a86f-b28d72f531c9', 'name': None, 'version': None}, 'dataPath': None, 'uri': None, 'type': None}, 'mechanism': 'Direct', 'environmentVariableName': 'testing_data', 'pathOnCompute': None, 'overwrite': False, 'options': None}}, 'outputData': {}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'instanceTypes': [], 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'text-classificiation-env', 'version': '1', 'assetId': 'azureml://locations/eastus2/workspaces/9634b616-29cb-4345-ae22-4be4e4bfe009/environments/text-classificiation-env/versions/1', 'autoRebuild': True, 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'name': 'textclassification_env', 'dependencies': ['python=3.8.5', 'scikit-learn', 'ipykernel', 'matplotlib', 'pandas', 'pip', {'pip': ['azureml-defaults', 'numpy', 'joblib', 'sklearn']}]}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20221101.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': 'D2', 'imageVersion': 'pytorch-1.7.0', 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'sshPublicKeys': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard', 'userAlias': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {'AML_PARAMETER_model_name': 'text_classification_001', 'AML_PARAMETER_model_desc': 'text_classification_001 description'}, 'applicationEndpoints': {}, 'parameters': []}, 'logFiles': {'logs/azureml/dataprep/0/backgroundProcess.log': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.514c5a93-a903-4041-84dd-53e93ce5f861/logs/azureml/dataprep/0/backgroundProcess.log?sv=2019-07-07&sr=b&sig=Sl1U%2F0Wt69bPNkCS35eyLbsl0arC8HLIdMWzCF3sQuY%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-02T23%3A14%3A55Z&ske=2023-02-04T07%3A24%3A55Z&sks=b&skv=2019-07-07&st=2023-02-03T06%3A12%3A36Z&se=2023-02-03T14%3A22%3A36Z&sp=r', 'logs/azureml/dataprep/0/backgroundProcess_Telemetry.log': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.514c5a93-a903-4041-84dd-53e93ce5f861/logs/azureml/dataprep/0/backgroundProcess_Telemetry.log?sv=2019-07-07&sr=b&sig=Bo16EUIj%2BPP3ubf5g4XH3ztk7zwEi%2F23CjOe37xGYK0%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-02T23%3A14%3A55Z&ske=2023-02-04T07%3A24%3A55Z&sks=b&skv=2019-07-07&st=2023-02-03T06%3A12%3A36Z&se=2023-02-03T14%3A22%3A36Z&sp=r', 'logs/azureml/dataprep/0/rslex.log.2023-02-03-06': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.514c5a93-a903-4041-84dd-53e93ce5f861/logs/azureml/dataprep/0/rslex.log.2023-02-03-06?sv=2019-07-07&sr=b&sig=uKwYsz%2Bn6MaVdkUVfYJWvd3YmqFeTuVTZS2BmT%2FHGL8%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-02T23%3A14%3A55Z&ske=2023-02-04T07%3A24%3A55Z&sks=b&skv=2019-07-07&st=2023-02-03T06%3A12%3A36Z&se=2023-02-03T14%3A22%3A36Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.514c5a93-a903-4041-84dd-53e93ce5f861/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=QagZSsrvXt6HAcjd6Ln7OU5nudTOOQI3XCVoUjJm1gE%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-02T23%3A14%3A55Z&ske=2023-02-04T07%3A24%3A55Z&sks=b&skv=2019-07-07&st=2023-02-03T06%3A12%3A36Z&se=2023-02-03T14%3A22%3A36Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.514c5a93-a903-4041-84dd-53e93ce5f861/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=ARrhtzn%2FZC8l%2F7%2BRpgxLpxoUIrJpO2vx86dof3q9ixs%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-02T23%3A14%3A55Z&ske=2023-02-04T07%3A24%3A55Z&sks=b&skv=2019-07-07&st=2023-02-03T06%3A12%3A36Z&se=2023-02-03T14%3A22%3A36Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.514c5a93-a903-4041-84dd-53e93ce5f861/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=L%2BcvrystZ6iECSYbs%2FGJTjQMcdhv5QU1MfJxdpEj0%2Bg%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-02T23%3A14%3A55Z&ske=2023-02-04T07%3A24%3A55Z&sks=b&skv=2019-07-07&st=2023-02-03T06%3A12%3A36Z&se=2023-02-03T14%3A22%3A36Z&sp=r', 'user_logs/std_log.txt': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.514c5a93-a903-4041-84dd-53e93ce5f861/user_logs/std_log.txt?sv=2019-07-07&sr=b&sig=MYs9YrLWi8XcPCe8UIg5nX%2Fvhns%2BSWomE8Cfeemlxp8%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-02T23%3A14%3A55Z&ske=2023-02-04T07%3A24%3A55Z&sks=b&skv=2019-07-07&st=2023-02-03T06%3A12%3A44Z&se=2023-02-03T14%3A22%3A44Z&sp=r', 'system_logs/cs_capability/cs-capability.log': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.514c5a93-a903-4041-84dd-53e93ce5f861/system_logs/cs_capability/cs-capability.log?sv=2019-07-07&sr=b&sig=1axILo5I7iHslFWZ04d%2F619rFEZQ6hdya9cPyWVuEcg%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-02T23%3A14%3A55Z&ske=2023-02-04T07%3A24%3A55Z&sks=b&skv=2019-07-07&st=2023-02-03T06%3A12%3A44Z&se=2023-02-03T14%3A22%3A44Z&sp=r', 'system_logs/data_capability/data-capability.log': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.514c5a93-a903-4041-84dd-53e93ce5f861/system_logs/data_capability/data-capability.log?sv=2019-07-07&sr=b&sig=8K%2B2yWIX03OODvHewR8V5JI1uNzIhTlNz%2FAFQfGoQt8%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-02T23%3A14%3A55Z&ske=2023-02-04T07%3A24%3A55Z&sks=b&skv=2019-07-07&st=2023-02-03T06%3A12%3A44Z&se=2023-02-03T14%3A22%3A44Z&sp=r', 'system_logs/data_capability/rslex.log.2023-02-03-06': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.514c5a93-a903-4041-84dd-53e93ce5f861/system_logs/data_capability/rslex.log.2023-02-03-06?sv=2019-07-07&sr=b&sig=hgQAZ58tw8yqgbSru%2Bq8fSVKin1c0ZLgM9TClMC7u2M%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-02T23%3A14%3A55Z&ske=2023-02-04T07%3A24%3A55Z&sks=b&skv=2019-07-07&st=2023-02-03T06%3A12%3A44Z&se=2023-02-03T14%3A22%3A44Z&sp=r', 'system_logs/hosttools_capability/hosttools-capability.log': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.514c5a93-a903-4041-84dd-53e93ce5f861/system_logs/hosttools_capability/hosttools-capability.log?sv=2019-07-07&sr=b&sig=dCQ3R9EiP1RIn6r7naLcqC0kIlrDKMn8u%2BTjrwc1N1Y%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-02T23%3A14%3A55Z&ske=2023-02-04T07%3A24%3A55Z&sks=b&skv=2019-07-07&st=2023-02-03T06%3A12%3A44Z&se=2023-02-03T14%3A22%3A44Z&sp=r', 'system_logs/lifecycler/execution-wrapper.log': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.514c5a93-a903-4041-84dd-53e93ce5f861/system_logs/lifecycler/execution-wrapper.log?sv=2019-07-07&sr=b&sig=ReG3wVclEEYFkFw5yFzMJ2tPIwn02Xv5hX4MN6z3mVY%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-02T23%3A14%3A55Z&ske=2023-02-04T07%3A24%3A55Z&sks=b&skv=2019-07-07&st=2023-02-03T06%3A12%3A44Z&se=2023-02-03T14%3A22%3A44Z&sp=r', 'system_logs/lifecycler/lifecycler.log': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.514c5a93-a903-4041-84dd-53e93ce5f861/system_logs/lifecycler/lifecycler.log?sv=2019-07-07&sr=b&sig=rGlzAlMlzXRoe0aLd7HCm1oNxUkTQwCT6AAbM03wLkA%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-02T23%3A14%3A55Z&ske=2023-02-04T07%3A24%3A55Z&sks=b&skv=2019-07-07&st=2023-02-03T06%3A12%3A44Z&se=2023-02-03T14%3A22%3A44Z&sp=r', 'system_logs/metrics_capability/metrics-capability.log': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.514c5a93-a903-4041-84dd-53e93ce5f861/system_logs/metrics_capability/metrics-capability.log?sv=2019-07-07&sr=b&sig=QGeNdPRkcb%2BVIvjK5t6JIs9di%2BEt4AUFc7b3rOlTJxs%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-02T23%3A14%3A55Z&ske=2023-02-04T07%3A24%3A55Z&sks=b&skv=2019-07-07&st=2023-02-03T06%3A12%3A44Z&se=2023-02-03T14%3A22%3A44Z&sp=r', 'system_logs/snapshot_capability/snapshot-capability.log': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.514c5a93-a903-4041-84dd-53e93ce5f861/system_logs/snapshot_capability/snapshot-capability.log?sv=2019-07-07&sr=b&sig=JgT6oY8N%2FkoicSE0XXBfXy5fZ%2F3HD1eYiQMZUOPWkxA%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-02T23%3A14%3A55Z&ske=2023-02-04T07%3A24%3A55Z&sks=b&skv=2019-07-07&st=2023-02-03T06%3A12%3A44Z&se=2023-02-03T14%3A22%3A44Z&sp=r'}, 'submittedBy': 'e51aa7c8-2975-4062-85fe-af95c0b8e461'}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': '3913a927-924b-44f3-a119-abe8486aafea', 'status': 'Completed', 'startTimeUtc': '2023-02-03T06:21:33.890386Z', 'endTimeUtc': '2023-02-03T06:22:43.69354Z', 'services': {}, 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{\"raw_file_location\":\"spam-data/spamformodel.csv\",\"model_name\":\"text_classification_001\",\"model_desc\":\"text_classification_001 description\"}', 'azureml.continue_on_step_failure': 'False', 'azureml.continue_on_failed_optional_input': 'True', 'azureml.pipelineComponent': 'pipelinerun', 'azureml.pipelines.stages': '{\"Initialization\":null,\"Execution\":{\"StartTime\":\"2023-02-03T06:21:34.1103528+00:00\",\"EndTime\":\"2023-02-03T06:22:43.6135353+00:00\",\"Status\":\"Finished\"}}'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.3913a927-924b-44f3-a119-abe8486aafea/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=YcnGcBDeJyg%2BM%2FhPBJy8%2BqpS4a82mBQ4z%2FRd%2FC1J8BU%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-02T23%3A14%3A55Z&ske=2023-02-04T07%3A24%3A55Z&sks=b&skv=2019-07-07&st=2023-02-03T06%3A11%3A59Z&se=2023-02-03T14%3A21%3A59Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.3913a927-924b-44f3-a119-abe8486aafea/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=sRkyyN0pGXaG%2Fs14o8tKuO6%2FDLWm%2FewPwVOfB9RYVw4%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-02T23%3A14%3A55Z&ske=2023-02-04T07%3A24%3A55Z&sks=b&skv=2019-07-07&st=2023-02-03T06%3A11%3A59Z&se=2023-02-03T14%3A21%3A59Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.3913a927-924b-44f3-a119-abe8486aafea/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=G7VJOKmNQ4acN4lHdukEpYRnRXeoYOc2he0yQzzM0Mg%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-02T23%3A14%3A55Z&ske=2023-02-04T07%3A24%3A55Z&sks=b&skv=2019-07-07&st=2023-02-03T06%3A11%3A59Z&se=2023-02-03T14%3A21%3A59Z&sp=r'}, 'submittedBy': 'e51aa7c8-2975-4062-85fe-af95c0b8e461'}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create Pipeline Steps\n",
    "pipeline = Pipeline(workspace=ws, steps=[train_model_step, evaluate_and_register_step])\n",
    "if run_by_notebook:\n",
    "    experiment = Experiment(ws, 'AML_Manual_PipelineTraining')\n",
    "else:\n",
    "    experiment = Experiment(ws, 'AML_AutoDevOps_PipelineTraining')\n",
    "run = experiment.submit(pipeline)\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "97fa612d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inital_model_version = 4\n",
      "final_model_version= 4\n",
      "{'runId': '3913a927-924b-44f3-a119-abe8486aafea', 'status': 'Completed', 'startTimeUtc': '2023-02-03T06:21:33.890386Z', 'endTimeUtc': '2023-02-03T06:22:43.69354Z', 'services': {}, 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{\"raw_file_location\":\"spam-data/spamformodel.csv\",\"model_name\":\"text_classification_001\",\"model_desc\":\"text_classification_001 description\"}', 'azureml.continue_on_step_failure': 'False', 'azureml.continue_on_failed_optional_input': 'True', 'azureml.pipelineComponent': 'pipelinerun', 'azureml.pipelines.stages': '{\"Initialization\":null,\"Execution\":{\"StartTime\":\"2023-02-03T06:21:34.1103528+00:00\",\"EndTime\":\"2023-02-03T06:22:43.6135353+00:00\",\"Status\":\"Finished\"}}'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.3913a927-924b-44f3-a119-abe8486aafea/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=YcnGcBDeJyg%2BM%2FhPBJy8%2BqpS4a82mBQ4z%2FRd%2FC1J8BU%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-02T23%3A14%3A55Z&ske=2023-02-04T07%3A24%3A55Z&sks=b&skv=2019-07-07&st=2023-02-03T06%3A11%3A59Z&se=2023-02-03T14%3A21%3A59Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.3913a927-924b-44f3-a119-abe8486aafea/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=sRkyyN0pGXaG%2Fs14o8tKuO6%2FDLWm%2FewPwVOfB9RYVw4%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-02T23%3A14%3A55Z&ske=2023-02-04T07%3A24%3A55Z&sks=b&skv=2019-07-07&st=2023-02-03T06%3A11%3A59Z&se=2023-02-03T14%3A21%3A59Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.3913a927-924b-44f3-a119-abe8486aafea/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=G7VJOKmNQ4acN4lHdukEpYRnRXeoYOc2he0yQzzM0Mg%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-02T23%3A14%3A55Z&ske=2023-02-04T07%3A24%3A55Z&sks=b&skv=2019-07-07&st=2023-02-03T06%3A11%3A59Z&se=2023-02-03T14%3A21%3A59Z&sp=r'}, 'submittedBy': 'e51aa7c8-2975-4062-85fe-af95c0b8e461'}\n",
      "3913a927-924b-44f3-a119-abe8486aafea\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "try:\n",
    "    final_model = Model(ws, model_name_to_register)\n",
    "    final_model_version = final_model.version\n",
    "except WebserviceException :\n",
    "    final_model_version = 0\n",
    "    \n",
    "print('inital_model_version = ' + str(inital_model_version))\n",
    "print('final_model_version= ' + str(final_model_version))\n",
    "\n",
    "status = run.get_status()\n",
    "run_details = run.get_details()\n",
    "\n",
    "print((run_details))\n",
    "print(run_details['runId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "c5e98a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if final_model_version > 0 and (inital_model_version != final_model_version):\n",
    "    deploy = 'deploy'\n",
    "    model_details = {\n",
    "        \"name\" : final_model.name,\n",
    "        \"version\": final_model.version,\n",
    "        \"properties\": final_model.properties,\n",
    "        \"nextstep\": \"deploy\"\n",
    "    }\n",
    "    print(model_details)\n",
    "else:\n",
    "    deploy = 'no'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "e13d8198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "0.9783333333333334\n",
      "prec\n",
      "0.9784996490863248\n",
      "recall\n",
      "0.9783333333333334\n",
      "{'Accuracy': '0.9783333333333334', 'prec': '0.9784996490863248', 'recall': '0.9783333333333334'}\n"
     ]
    }
   ],
   "source": [
    "for x in final_model.properties:\n",
    "    print(x)\n",
    "    print(final_model.properties[x])\n",
    "\n",
    "print (final_model.properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "95409c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new model registered\n",
      "{'runId': '563036a1-ae55-48b9-8d82-40c4795859df', 'status': 'Completed', 'startTimeUtc': '2023-02-03T05:36:11.591272Z', 'endTimeUtc': '2023-02-03T05:37:17.045518Z', 'services': {}, 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{\"raw_file_location\":\"spam-data/spamformodel.csv\",\"model_name\":\"text_classification_001\",\"model_desc\":\"text_classification_001 description\"}', 'azureml.continue_on_step_failure': 'False', 'azureml.continue_on_failed_optional_input': 'True', 'azureml.pipelineComponent': 'pipelinerun', 'azureml.pipelines.stages': '{\"Initialization\":null,\"Execution\":{\"StartTime\":\"2023-02-03T05:36:11.9214802+00:00\",\"EndTime\":\"2023-02-03T05:37:16.9771452+00:00\",\"Status\":\"Finished\"}}'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.563036a1-ae55-48b9-8d82-40c4795859df/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=CHfsGVWMhvtlqDG3zqPNQqo5gxZg1U5xNOF9Vwo8j30%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-02T23%3A14%3A55Z&ske=2023-02-04T07%3A24%3A55Z&sks=b&skv=2019-07-07&st=2023-02-03T05%3A27%3A19Z&se=2023-02-03T13%3A37%3A19Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.563036a1-ae55-48b9-8d82-40c4795859df/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=9GEyAzpQJVNoxy36fWxueallNk2oR9j5DhKSDv0f9mQ%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-02T23%3A14%3A55Z&ske=2023-02-04T07%3A24%3A55Z&sks=b&skv=2019-07-07&st=2023-02-03T05%3A27%3A19Z&se=2023-02-03T13%3A37%3A19Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.563036a1-ae55-48b9-8d82-40c4795859df/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=2q36gxEmm0gR3IDxpuTHuSy8NXq3ALWJQWt0U9d4nPk%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-02T23%3A14%3A55Z&ske=2023-02-04T07%3A24%3A55Z&sks=b&skv=2019-07-07&st=2023-02-03T05%3A27%3A19Z&se=2023-02-03T13%3A37%3A19Z&sp=r'}, 'submittedBy': 'e51aa7c8-2975-4062-85fe-af95c0b8e461'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "outputfolder = 'run_outputs'\n",
    "os.makedirs(outputfolder, exist_ok=True)\n",
    "\n",
    "if (final_model_version != inital_model_version):\n",
    "    print('new model registered')\n",
    "    with open(os.path.join(outputfolder, 'deploy_details.json'), \"w+\") as f:\n",
    "        f.write(str(model_details))\n",
    "    model_name = model_name_to_register\n",
    "    model_list = Model.list(ws, name=model_name_to_register, latest=True)\n",
    "    model_path = model_list[0].download(exist_ok=True)\n",
    "    model_file_name = model_name_to_register + '.pkl'\n",
    "    shutil.copyfile(model_file_name,  os.path.join(outputfolder,model_file_name))\n",
    "    \n",
    "    #create model.yml file.\n",
    "    with open(os.path.join(outputfolder, 'model.yml'), \"w+\") as f:\n",
    "        f.write('$schema: https://azuremlschemas.azureedge.net/latest/model.schema.json \\n')\n",
    "        f.write('name: ' + model_details['name'] + '\\n')\n",
    "        f.write('path: ' + model_name_to_register + '.pkl \\n')\n",
    "        f.write('description: Model created from local file. \\n')\n",
    "        if len(final_model.properties) > 0:\n",
    "            f.write('properties: ')\n",
    "            f.write(json.dumps(final_model.properties))\n",
    "            f.write('\\n')\n",
    "            f.write('tags: ')\n",
    "            f.write(json.dumps(final_model.properties))\n",
    "            \n",
    "    \n",
    "with open(os.path.join(outputfolder, 'run_details.json'), \"w+\") as f:\n",
    "    print(run_details)\n",
    "    f.write(str(run_details))\n",
    "\n",
    "with open(os.path.join(outputfolder, \"run_number.json\"), \"w+\") as f:\n",
    "    f.write(run_details['runId'])\n",
    "    \n",
    "with open(os.path.join(outputfolder, \"deploy.txt\"), \"w+\") as f:\n",
    "    f.write(deploy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "170fd2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deploy Email Classification Training Pipeline\n",
      "using existing PipelineEndpoint...\n"
     ]
    }
   ],
   "source": [
    "from azureml.pipeline.core import PipelineEndpoint\n",
    "\n",
    "def published_pipeline_to_pipeline_endpoint(\n",
    "    workspace,\n",
    "    published_pipeline,\n",
    "    pipeline_endpoint_name,\n",
    "    pipeline_endpoint_description=\"Endpoint to Email Classification Training pipeline\",\n",
    "):\n",
    "    try:\n",
    "        pipeline_endpoint = PipelineEndpoint.get(\n",
    "            workspace=workspace, name=pipeline_endpoint_name\n",
    "        )\n",
    "        print(\"using existing PipelineEndpoint...\")\n",
    "        pipeline_endpoint.add_default(published_pipeline)\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        # create PipelineEndpoint if it doesn't exist\n",
    "        print(\"PipelineEndpoint does not exist, creating one for you...\")\n",
    "        pipeline_endpoint = PipelineEndpoint.publish(\n",
    "            workspace=workspace,\n",
    "            name=pipeline_endpoint_name,\n",
    "            pipeline=published_pipeline,\n",
    "            description=pipeline_endpoint_description\n",
    "        )\n",
    "\n",
    "if deploy == 'deploy':\n",
    "    print('deploy Email Classification Training Pipeline')\n",
    "    pipeline_endpoint_name = 'Email Classification Training Pipeline'\n",
    "    pipeline_endpoint_description = 'Endpoint to Email Classification Training pipeline'\n",
    "\n",
    "    published_pipeline = pipeline.publish(name=pipeline_endpoint_name,\n",
    "                                         description=pipeline_endpoint_description,\n",
    "                                         continue_on_step_failure=False)\n",
    "\n",
    "    published_pipeline_to_pipeline_endpoint(\n",
    "        workspace=ws,\n",
    "        published_pipeline=published_pipeline,\n",
    "        pipeline_endpoint_name=pipeline_endpoint_name,\n",
    "        pipeline_endpoint_description=pipeline_endpoint_description\n",
    "    )\n",
    "else:\n",
    "    print('do not publish pipeline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "364d6f8b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (291600845.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[148], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    Do Not run\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "Do Not run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95460011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "34fee1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py38/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator CountVectorizer from version 1.2.0 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "255",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[155], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m model_list \u001b[38;5;241m=\u001b[39m Model\u001b[38;5;241m.\u001b[39mlist(ws, name\u001b[38;5;241m=\u001b[39mmodel_name_to_register, latest\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     29\u001b[0m model_path \u001b[38;5;241m=\u001b[39m model_list[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdownload(exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 31\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# inf_df = pd.read_csv('./spaminference.csv')\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# print(inferencing_data_df.shape)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# # Make predictions with new dataframe\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# predictions = model.predict(X)\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/joblib/numpy_pickle.py:605\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    599\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, _basestring):\n\u001b[1;32m    600\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[1;32m    601\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[1;32m    602\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n\u001b[1;32m    603\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m load_compatibility(fobj)\n\u001b[0;32m--> 605\u001b[0m             obj \u001b[38;5;241m=\u001b[39m \u001b[43m_unpickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmmap_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/joblib/numpy_pickle.py:529\u001b[0m, in \u001b[0;36m_unpickle\u001b[0;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[1;32m    527\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 529\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    530\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m unpickler\u001b[38;5;241m.\u001b[39mcompat_mode:\n\u001b[1;32m    531\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe file \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has been generated with a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    532\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjoblib version less than 0.10. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    533\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease regenerate this pickle file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    534\u001b[0m                       \u001b[38;5;241m%\u001b[39m filename,\n\u001b[1;32m    535\u001b[0m                       \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/pickle.py:1212\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1210\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[1;32m   1211\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, bytes_types)\n\u001b[0;32m-> 1212\u001b[0m         \u001b[43mdispatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _Stop \u001b[38;5;28;01mas\u001b[39;00m stopinst:\n\u001b[1;32m   1214\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stopinst\u001b[38;5;241m.\u001b[39mvalue\n",
      "\u001b[0;31mKeyError\u001b[0m: 255"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "import argparse\n",
    "from azureml.core import Run\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Get model from workspace - the code below will always retrieve the latest version of the model; specific versions can be targeted.\n",
    "model_list = Model.list(ws, name=model_name_to_register, latest=True)\n",
    "model_path = model_list[0].download(exist_ok=True)\n",
    "\n",
    "model = joblib.load(model_path)\n",
    "\n",
    "# inf_df = pd.read_csv('./spaminference.csv')\n",
    "\n",
    "# print(inferencing_data_df.shape)\n",
    "\n",
    "\n",
    "# X = inferencing_data_df['text']\n",
    "# # Make predictions with new dataframe\n",
    "# predictions = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "27c7ed5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'text_classification_001.pkl'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "2c1983e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "255",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[154], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/joblib/numpy_pickle.py:605\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    599\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, _basestring):\n\u001b[1;32m    600\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[1;32m    601\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[1;32m    602\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n\u001b[1;32m    603\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m load_compatibility(fobj)\n\u001b[0;32m--> 605\u001b[0m             obj \u001b[38;5;241m=\u001b[39m \u001b[43m_unpickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmmap_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/joblib/numpy_pickle.py:529\u001b[0m, in \u001b[0;36m_unpickle\u001b[0;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[1;32m    527\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 529\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    530\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m unpickler\u001b[38;5;241m.\u001b[39mcompat_mode:\n\u001b[1;32m    531\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe file \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has been generated with a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    532\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjoblib version less than 0.10. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    533\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease regenerate this pickle file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    534\u001b[0m                       \u001b[38;5;241m%\u001b[39m filename,\n\u001b[1;32m    535\u001b[0m                       \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/pickle.py:1212\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1210\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[1;32m   1211\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, bytes_types)\n\u001b[0;32m-> 1212\u001b[0m         \u001b[43mdispatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _Stop \u001b[38;5;28;01mas\u001b[39;00m stopinst:\n\u001b[1;32m   1214\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stopinst\u001b[38;5;241m.\u001b[39mvalue\n",
      "\u001b[0;31mKeyError\u001b[0m: 255"
     ]
    }
   ],
   "source": [
    "model = joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "0dd61565",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModelNotFoundException",
     "evalue": "ModelNotFoundException:\n\tMessage: Model tester not found in cache at azureml-models or in current working directory /mnt/batch/tasks/shared/LS_root/mounts/clusters/memasanz1/code/Users/memasanz/email_text_classification. For more info, set logging level to DEBUG.\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Model tester not found in cache at azureml-models or in current working directory /mnt/batch/tasks/shared/LS_root/mounts/clusters/memasanz1/code/Users/memasanz/email_text_classification. For more info, set logging level to DEBUG.\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelNotFoundException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[156], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[43mModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_model_path\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtester\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(model_path)\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/model.py:807\u001b[0m, in \u001b[0;36mModel.get_model_path\u001b[0;34m(model_name, version, _workspace)\u001b[0m\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Model\u001b[38;5;241m.\u001b[39m_get_model_path_remote(model_name, version, active_workspace)\n\u001b[1;32m    806\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 807\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_model_path_local\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mversion\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/model.py:828\u001b[0m, in \u001b[0;36mModel._get_model_path_local\u001b[0;34m(model_name, version)\u001b[0m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;66;03m# Probing azureml-models/<name>\u001b[39;00m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(candidate_model_path):\n\u001b[0;32m--> 828\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_model_path_local_from_root\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    830\u001b[0m     \u001b[38;5;66;03m# Probing azureml-models/<name> exists, probing version\u001b[39;00m\n\u001b[1;32m    831\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m version \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/model.py:870\u001b[0m, in \u001b[0;36mModel._get_model_path_local_from_root\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(candidate_model_path):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m candidate_model_path\n\u001b[0;32m--> 870\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ModelNotFoundException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m not found in cache at \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m or in current working directory \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    871\u001b[0m                              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor more info, set logging level to DEBUG.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(model_name, MODELS_DIR,\n\u001b[1;32m    872\u001b[0m                                                                                  os\u001b[38;5;241m.\u001b[39mgetcwd()))\n",
      "\u001b[0;31mModelNotFoundException\u001b[0m: ModelNotFoundException:\n\tMessage: Model tester not found in cache at azureml-models or in current working directory /mnt/batch/tasks/shared/LS_root/mounts/clusters/memasanz1/code/Users/memasanz/email_text_classification. For more info, set logging level to DEBUG.\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Model tester not found in cache at azureml-models or in current working directory /mnt/batch/tasks/shared/LS_root/mounts/clusters/memasanz1/code/Users/memasanz/email_text_classification. For more info, set logging level to DEBUG.\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "model_path = Model.get_model_path('tester')\n",
    "model = joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b596bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
