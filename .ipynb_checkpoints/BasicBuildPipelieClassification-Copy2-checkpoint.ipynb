{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "535c32aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import azureml.core\n",
    "from azureml.core import Workspace, Experiment, Datastore, Environment, Dataset\n",
    "from azureml.core.authentication import ServicePrincipalAuthentication\n",
    "from azureml.core import Workspace, Experiment, Datastore, Environment, Dataset\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute, DataFactoryCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\n",
    "from azureml.pipeline.core import Pipeline, PipelineParameter, PipelineData\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "from azureml.pipeline.core import PipelineParameter, PipelineData\n",
    "from azureml.data.output_dataset_config import OutputTabularDatasetConfig, OutputDatasetConfig, OutputFileDatasetConfig\n",
    "from azureml.data.datapath import DataPath\n",
    "from azureml.data.data_reference import DataReference\n",
    "from azureml.data.sql_data_reference import SqlDataReference\n",
    "from azureml.pipeline.steps import DataTransferStep\n",
    "import logging\n",
    "from azureml.core.model import Model\n",
    "from azureml.exceptions import WebserviceException\n",
    "import os, shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4e75d2",
   "metadata": {},
   "source": [
    "## Setting up Key Vault Values - Do not keep these around - run 1 time only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1466b92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import azureml.core\n",
    "# import os, shutil\n",
    "# from azureml.core import Workspace, Experiment, Datastore, Environment, Dataset\n",
    "# from azureml.core.authentication import ServicePrincipalAuthentication\n",
    "\n",
    "# os.environ.setdefault('tenantId', 'XXXX')\n",
    "# os.environ.setdefault('servicePrincipalId', 'XXXX')\n",
    "# os.environ.setdefault('servicePrincipalPassword', 'XXXXXX')\n",
    "# os.environ.setdefault('wsName', 'XXX')\n",
    "# os.environ.setdefault('subscriptionId', 'XXXXX')\n",
    "# os.environ.setdefault('resourceGroup', 'XXXXX')\n",
    "\n",
    "\n",
    "# environment_variables = ['tenantId', 'servicePrincipalId', 'servicePrincipalPassword', 'wsName', \n",
    "#                          'subscriptionId', 'resourceGroup']\n",
    "\n",
    "# envs = {}\n",
    "\n",
    "# for x in environment_variables:\n",
    "#     print(x, \"=\", os.environ.get(x))\n",
    "#     envs[x] = os.environ.get(x)\n",
    "\n",
    "\n",
    "# sp = ServicePrincipalAuthentication(tenant_id=envs['tenantId'], # tenantID\n",
    "#                                     service_principal_id=envs['servicePrincipalId'], # clientId\n",
    "#                                     service_principal_password=envs['servicePrincipalPassword']) # clientSecret\n",
    "\n",
    "# ws = Workspace.get(name=envs['wsName'],\n",
    "#                    auth=sp,\n",
    "#                    subscription_id=envs['subscriptionId'],\n",
    "#                    resource_group=envs['resourceGroup'])\n",
    "# ws.get_details()\n",
    "# keyvault = ws.get_default_keyvault()\n",
    "\n",
    "# for x in environment_variables:\n",
    "#     print(x, \"=\", os.environ.get(x))\n",
    "#     keyvault.set_secret(name = x, value = envs[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb88252c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieve from key vault, value is None: tenantId\n",
      "Ready to use Azure ML 1.48.0 to work with aml-dev\n",
      "Run By Notebook:True\n"
     ]
    }
   ],
   "source": [
    "def get_environment_variables():\n",
    "    global envs\n",
    "    global run_by_notebook \n",
    "    run_by_notebook = False\n",
    "    environment_variables = ['tenantId', 'servicePrincipalId', 'servicePrincipalPassword', 'wsName', \n",
    "                         'subscriptionId', 'resourceGroup']\n",
    "    envs = {}\n",
    "    for x in environment_variables:\n",
    "        if os.environ.get(x) == None:\n",
    "            #get the values from keyvault\n",
    "            run_by_notebook = True\n",
    "            print('retrieve from key vault, value is None: ' + x)\n",
    "            ws = Workspace.from_config()\n",
    "            keyvault = ws.get_default_keyvault()\n",
    "            kv_results = keyvault.get_secrets(environment_variables)\n",
    "            envs = kv_results\n",
    "            for x in envs:\n",
    "                os.environ.setdefault(x, envs[x])\n",
    "            exit\n",
    "        else:\n",
    "            envs[x] = os.environ.get(x)\n",
    "    return run_by_notebook\n",
    "\n",
    "\n",
    "\n",
    "get_environment_variables()\n",
    "sp = ServicePrincipalAuthentication(tenant_id=envs['tenantId'], # tenantID\n",
    "                                    service_principal_id=envs['servicePrincipalId'], # clientId\n",
    "                                    service_principal_password=envs['servicePrincipalPassword']) # clientSecret\n",
    "ws = Workspace.get(name=envs['wsName'],\n",
    "                       auth=sp,\n",
    "                       subscription_id=envs['subscriptionId'],\n",
    "                       resource_group=envs['resourceGroup'])\n",
    "ws.get_details()\n",
    "\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))\n",
    "print('Run By Notebook:' + str(run_by_notebook))\n",
    "# Get the default datastore\n",
    "default_ds = ws.get_default_datastore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b578401e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_name = 'aml-cluster001'\n",
    "model_name_to_register = 'text_classification_001'\n",
    "experiment_folder = 'text_classificatin_example'\n",
    "conda_yml_file = 'textclassification_env.yml'\n",
    "registered_env_name = \"text-classificiation-env\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c502e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Select AML Compute Cluster\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "\n",
    "try:\n",
    "    # Check for existing compute target\n",
    "    pipeline_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # If it doesn't already exist, create it\n",
    "    try:\n",
    "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
    "        pipeline_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "        pipeline_cluster.wait_for_completion(show_output=True)\n",
    "    except Exception as ex:\n",
    "        print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26731050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inital_model_version = 4\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    initial_model = Model(ws, model_name_to_register)\n",
    "    inital_model_version = initial_model.version\n",
    "except WebserviceException :\n",
    "    inital_model_version = 0\n",
    "print('inital_model_version = ' + str(inital_model_version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffd71ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_classificatin_example\n",
      "continue run_outputs directory does not exits\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "# Create a folder for the pipeline step files\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "\n",
    "print(experiment_folder)\n",
    "\n",
    "run_path = './run_outputs'\n",
    "try:\n",
    "    shutil.rmtree(run_path)\n",
    "except:\n",
    "    print('continue run_outputs directory does not exits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51e07df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"assetId\": \"azureml://locations/eastus2/workspaces/9634b616-29cb-4345-ae22-4be4e4bfe009/environments/text-classificiation-env/versions/1\",\n",
       "    \"databricks\": {\n",
       "        \"eggLibraries\": [],\n",
       "        \"jarLibraries\": [],\n",
       "        \"mavenLibraries\": [],\n",
       "        \"pypiLibraries\": [],\n",
       "        \"rcranLibraries\": []\n",
       "    },\n",
       "    \"docker\": {\n",
       "        \"arguments\": [],\n",
       "        \"baseDockerfile\": null,\n",
       "        \"baseImage\": \"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20221101.v1\",\n",
       "        \"baseImageRegistry\": {\n",
       "            \"address\": null,\n",
       "            \"password\": null,\n",
       "            \"registryIdentity\": null,\n",
       "            \"username\": null\n",
       "        },\n",
       "        \"buildContext\": null,\n",
       "        \"enabled\": false,\n",
       "        \"platform\": {\n",
       "            \"architecture\": \"amd64\",\n",
       "            \"os\": \"Linux\"\n",
       "        },\n",
       "        \"sharedVolumes\": true,\n",
       "        \"shmSize\": null\n",
       "    },\n",
       "    \"environmentVariables\": {\n",
       "        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n",
       "    },\n",
       "    \"inferencingStackVersion\": null,\n",
       "    \"name\": \"text-classificiation-env\",\n",
       "    \"python\": {\n",
       "        \"baseCondaEnvironment\": null,\n",
       "        \"condaDependencies\": {\n",
       "            \"dependencies\": [\n",
       "                \"python=3.8.5\",\n",
       "                \"scikit-learn\",\n",
       "                \"ipykernel\",\n",
       "                \"matplotlib\",\n",
       "                \"pandas\",\n",
       "                \"pip\",\n",
       "                {\n",
       "                    \"pip\": [\n",
       "                        \"azureml-defaults\",\n",
       "                        \"numpy\",\n",
       "                        \"joblib\",\n",
       "                        \"sklearn\"\n",
       "                    ]\n",
       "                }\n",
       "            ],\n",
       "            \"name\": \"textclassification_env\"\n",
       "        },\n",
       "        \"condaDependenciesFile\": null,\n",
       "        \"interpreterPath\": \"python\",\n",
       "        \"userManagedDependencies\": false\n",
       "    },\n",
       "    \"r\": null,\n",
       "    \"spark\": {\n",
       "        \"packages\": [],\n",
       "        \"precachePackages\": true,\n",
       "        \"repositories\": []\n",
       "    },\n",
       "    \"version\": \"1\"\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = Environment.from_conda_specification(registered_env_name, conda_yml_file)\n",
    "env.register(workspace=ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3ed7db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run configuration created.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    registered_env = Environment.get(ws, registered_env_name)\n",
    "    pipeline_run_config = RunConfiguration()\n",
    "    \n",
    "    # Use the compute you created above. \n",
    "    pipeline_run_config.target = pipeline_cluster\n",
    "\n",
    "    # Assign the environment to the run configuration\n",
    "    pipeline_run_config.environment = registered_env\n",
    "    print (\"Run configuration created.\")\n",
    "except Exception as e: \n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9811f05d",
   "metadata": {},
   "source": [
    "## Define Output datasets\n",
    "\n",
    "The OutputFileDatasetConfig object is a special kind of data reference that is used for interim storage locations that can be passed between pipeline steps, so you'll create one and use at as the output for the first step and the input for the second step. Note that you need to pass it as a script argument so your code can access the datastore location referenced by the data reference.\n",
    "\n",
    "Note, in all cases we specify the datastore that should hold the datasets and whether they should be registered following step completion or not. This can optionally be disabled by removing the register_on_complete() call.\n",
    "\n",
    "These can be viewed in the Datasets tab directly in the AML Portal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3111d211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'text_classification_001'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name_to_register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1006ffbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data  = OutputFileDatasetConfig(name='training_data', destination=(default_ds, model_name_to_register + '_training_data/{run-id}')).read_delimited_files().register_on_complete(name= model_name_to_register + '_training_data')\n",
    "testing_data   = OutputFileDatasetConfig(name='testing_data',  destination=(default_ds, model_name_to_register +  '_testing_data/{run-id}')).read_delimited_files().register_on_complete(name= model_name_to_register + '_testing_data')\n",
    "\n",
    "model_file     = PipelineData(name='model_file', datastore=default_ds)\n",
    "\n",
    "model_name         = PipelineParameter(\"model_name\", default_value= model_name_to_register)\n",
    "model_desc         = PipelineParameter(\"model_desc\", default_value=model_name_to_register + ' description')\n",
    "raw_file_location  = PipelineParameter(name=\"raw_file_location\", default_value='spam-data/spamformodel.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae2c4bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26038b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting text_classificatin_example/classifier_training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/classifier_training.py\n",
    "\n",
    "import argparse\n",
    "from azureml.core import Run, Workspace, Datastore, Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "\n",
    "def summarize_classification(y_test, y_pred, run):\n",
    "    acc = accuracy_score(y_test, y_pred, normalize=True) #how many predictions correct %\n",
    "    num_acc = accuracy_score(y_test, y_pred, normalize = False)\n",
    "    prec = precision_score(y_test, y_pred, average = 'weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    \n",
    "    run.log('total count', len(y_test))\n",
    "    run.log('acc count', num_acc)\n",
    "    run.log('Accuracy', acc)\n",
    "    run.log('prec', prec)\n",
    "    run.log('recall', recall)\n",
    "    \n",
    "    run.parent.log('acc count', num_acc)\n",
    "    run.parent.log('Accuracy', acc)\n",
    "    run.parent.log('prec', prec)\n",
    "    run.parent.log('recall', recall)\n",
    "\n",
    "\n",
    "    print('accuracy count:', num_acc)\n",
    "    print('accuracy score:', acc)\n",
    "    print('precision:', prec)\n",
    "    print('recall:', recall)\n",
    "    \n",
    "\n",
    "\n",
    "def getRuntimeArgs():\n",
    "    # Get script arguments\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--raw_file_location', dest='raw_file_location', required=True)\n",
    "    parser.add_argument('--training_data', dest='training_data', required=True)\n",
    "    parser.add_argument('--testing_data', dest='testing_data', required=True)\n",
    "    parser.add_argument('--model_file', dest='model_file', required=True)\n",
    "    parser.add_argument('--model_name', dest='model_name', required=True)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    return args\n",
    "\n",
    "def model_train(ds_df, run, training_data, testing_data):\n",
    "    \n",
    "    clf = Pipeline([\n",
    "                            ('count_vectorizer', CountVectorizer()),\n",
    "                            ('classifier', LogisticRegression(solver='lbfgs', max_iter=10000))\n",
    "                        ])\n",
    "    #output of convectorizer, feed to classifier\n",
    "    train, test = train_test_split(ds_df, test_size=0.2, random_state=0)\n",
    "\n",
    "    x_train = train['text']\n",
    "    y_train = train['labels']\n",
    "    \n",
    "    x_test = test['text']\n",
    "    y_test = test['labels']\n",
    "    \n",
    "    \n",
    "    print(train.head())\n",
    "\n",
    "\n",
    "    model = clf.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    \n",
    "    print('*************************')\n",
    "    print('model predictions:')\n",
    "    print(y_pred)\n",
    "    summarize_classification(y_test, y_pred, run)\n",
    "    \n",
    "    os.makedirs(training_data, exist_ok=True)\n",
    "    os.makedirs(testing_data, exist_ok=True)\n",
    "\n",
    "    test['results'] = y_pred\n",
    "    print('training_data = ' + training_data)\n",
    "    print('testing_data = ' + testing_data)\n",
    "    train.to_csv(os.path.join(training_data, 'training_data.csv'), index=False )\n",
    "    test.to_csv(os.path.join(testing_data, 'testing_data.csv'), index=False)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    args = getRuntimeArgs()\n",
    "    \n",
    "    raw_file_location = args.raw_file_location\n",
    "    training_data = args.training_data\n",
    "    testing_data = args.testing_data\n",
    "    model_file = args.model_file\n",
    "    model_name = args.model_name\n",
    "    \n",
    "    print(\"training_data =\" + training_data)\n",
    "    print('testing_data =' + testing_data)\n",
    "    # Get the experiment run context\n",
    "    run = Run.get_context()\n",
    "    ws = run.experiment.workspace\n",
    "    print(ws)\n",
    "    ds = ws.get_default_datastore()\n",
    "    \n",
    "    \n",
    "    print(\"Loading Data...\")\n",
    "    dataset = Dataset.Tabular.from_delimited_files(path = [(ds, raw_file_location)])\n",
    "    data = dataset.to_pandas_dataframe()\n",
    "    \n",
    "    \n",
    "    print(data.columns)\n",
    "    lr = model_train(data, run, training_data,  testing_data)\n",
    "    \n",
    "    os.makedirs('./outputs', exist_ok=True)\n",
    "    model_file_name = model_name  + '.pkl'\n",
    "    file_name = './outputs/' +model_file_name\n",
    "    \n",
    "    print(\"Joblib Version : \", joblib.__version__)\n",
    "    \n",
    "    joblib.dump(value=lr, filename=file_name)\n",
    "\n",
    "    #copy to pass model to next step as the model file\n",
    "    os.makedirs(model_file, exist_ok=True)\n",
    "    shutil.copyfile(file_name, os.path.join(model_file, model_file_name))\n",
    "\n",
    "    run.complete()\n",
    "\n",
    " \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ad4f74",
   "metadata": {},
   "source": [
    "## Train Model Python Script Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "911e98e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model_step = PythonScriptStep(\n",
    "    name='Get Data and Create Model',\n",
    "    script_name='classifier_training.py',\n",
    "    arguments =['--raw_file_location', raw_file_location,\n",
    "                '--training_data', training_data,\n",
    "                '--testing_data', testing_data,\n",
    "                '--model_file', model_file,\n",
    "                '--model_name', model_name\n",
    "               ],\n",
    "    inputs=[],\n",
    "    outputs=[model_file, training_data, testing_data],\n",
    "    compute_target=pipeline_cluster,\n",
    "    source_directory='./' + experiment_folder,\n",
    "    allow_reuse=False,\n",
    "    runconfig=pipeline_run_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28088b79",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd27090b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting text_classificatin_example/eval.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/eval.py\n",
    "\n",
    "from azureml.core import Run, Workspace, Datastore, Dataset\n",
    "from azureml.core.model import Model\n",
    "from azureml.data.datapath import DataPath\n",
    "\n",
    "import joblib\n",
    "import os\n",
    "import argparse\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.compute import ComputeTarget, AksCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.webservice import Webservice, AksWebservice\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(\"Evaluate model and register if more performant\")\n",
    "\n",
    "parser.add_argument('--model_name', dest='model_name', required=True)\n",
    "parser.add_argument('--model_file', dest = 'model_file',  required=True)\n",
    "parser.add_argument('--model_desc', dest = 'model_desc',  required=True)\n",
    "parser.add_argument('--deploy_file', dest='deploy_file', required=True)\n",
    "\n",
    "\n",
    "args, _ = parser.parse_known_args()\n",
    "model_name = args.model_name\n",
    "model_file = args.model_file\n",
    "model_desc = args.model_desc\n",
    "\n",
    "deploy_file = args.deploy_file\n",
    "\n",
    "#Get current run\n",
    "run = Run.get_context()\n",
    "\n",
    "#Get associated AML workspace\n",
    "ws = run.experiment.workspace\n",
    "\n",
    "#Get default datastore\n",
    "ds = ws.get_default_datastore()\n",
    "\n",
    "#Get metrics associated with current parent run\n",
    "metrics = run.get_metrics()\n",
    "\n",
    "print('current run metrics')\n",
    "for key in metrics.keys():\n",
    "        print(key, metrics.get(key))\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "print('parent run metrics')\n",
    "#Get metrics associated with current parent run\n",
    "metrics = run.parent.get_metrics()\n",
    "\n",
    "for key in metrics.keys():\n",
    "        print(key, metrics.get(key))\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "current_model_acc_count = float(metrics['acc count'])\n",
    "current_model_acc = float(metrics['Accuracy'])\n",
    "current_model_prec = float(metrics['prec'])\n",
    "current_model_recall = float(metrics['recall'])\n",
    "    \n",
    "\n",
    "# Get current model from workspace\n",
    "\n",
    "model_description = model_desc\n",
    "model_list = Model.list(ws, name=model_name, latest=True)\n",
    "first_registration = len(model_list)==0\n",
    "\n",
    "updated_tags = {'Accuracy': current_model_acc, 'prec': current_model_prec, 'recall': current_model_recall}\n",
    "\n",
    "\n",
    "print('updated tags')\n",
    "print(updated_tags)\n",
    "\n",
    "\n",
    "#upload model to the outputs directory\n",
    "relative_model_path = 'outputs'\n",
    "run.upload_folder(name=relative_model_path, path=model_file)\n",
    "\n",
    "model_file_name = model_name  + '.pkl'\n",
    "\n",
    "###################\n",
    "test_model = joblib.load(model_file + '/' + model_file_name)\n",
    "test_dataset = run.input_datasets['testing_data']\n",
    "df_test = test_dataset.to_pandas_dataframe()\n",
    "X = df_test['text']\n",
    "# Make predictions with new dataframe\n",
    "predictions = test_model.predict(X)\n",
    "print('predictions')\n",
    "print(predictions)\n",
    "#########################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#If no model exists register the current model\n",
    "if first_registration:\n",
    "    print('First model registration.')\n",
    "    model_reg = run.register_model(model_path='outputs/' + model_file_name, model_name=model_name,\n",
    "                   tags=updated_tags,\n",
    "                   properties=updated_tags)\n",
    "else:\n",
    "    #If a model has been registered previously, check to see if current model \n",
    "    #performs better. If so, register it.\n",
    "    print(dir(model_list[0]))\n",
    "    if float(model_list[0].tags['prec']) < current_model_prec:\n",
    "        print('New model performs better than existing model. Register it.')\n",
    "\n",
    "        model_reg = run.register_model(model_path='outputs/' + model_file_name, model_name=model_name,\n",
    "                   tags=updated_tags,\n",
    "                   properties=updated_tags)\n",
    "        \n",
    "        # Output accuracy to file\n",
    "        with open(deploy_file, 'w+') as f:\n",
    "            f.write(('deploy_model'))\n",
    "    \n",
    "    else:\n",
    "        print('New model does not perform better than existing model. Cancel run.')\n",
    "        \n",
    "        with open(deploy_file, 'w+') as f:\n",
    "            f.write(('do not deploy model'))\n",
    "            \n",
    "        run.complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a1bb502",
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_file = PipelineData(name='deploy_file', datastore=default_ds)\n",
    "\n",
    "evaluate_and_register_step = PythonScriptStep(\n",
    "    name='Evaluate and Register Model',\n",
    "    script_name='eval.py',\n",
    "    arguments=[\n",
    "        '--model_name', model_name,\n",
    "        '--model_file', model_file,\n",
    "        '--model_desc', model_desc,\n",
    "        '--deploy_file', deploy_file,       \n",
    "    ],\n",
    "    inputs=[model_file.as_input('model_file'),\n",
    "            training_data.as_input(name='training_data'),\n",
    "            testing_data.as_input(name='testing_data')\n",
    "           ],\n",
    "    outputs=[ deploy_file],\n",
    "    compute_target=pipeline_cluster,\n",
    "    source_directory='./' + experiment_folder,\n",
    "    allow_reuse=False,\n",
    "    runconfig=pipeline_run_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f64e8d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting text_classificatin_example/deploy.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/deploy.py\n",
    "\n",
    "import argparse\n",
    "from azureml.core import Workspace, Environment\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.run import Run\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import Webservice, AciWebservice\n",
    "from azureml.exceptions import WebserviceException\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Deploy arg parser')\n",
    "parser.add_argument('--scoring_file_output', type=str, help='File storing the scoring url')\n",
    "parser.add_argument('--deploy_file', type=str, help='File storing if model should be deployed')\n",
    "parser.add_argument('--environment_name', type=str,help='Environment name')\n",
    "parser.add_argument('--service_name', type=str,help='service name')\n",
    "parser.add_argument('--model_name', type=str,help='model name')\n",
    "\n",
    "\n",
    "\n",
    "args = parser.parse_args()\n",
    "scoring_url_file = args.scoring_file_output\n",
    "deploy_file      = args.deploy_file\n",
    "environment_name = args.environment_name\n",
    "service_name     = args.service_name\n",
    "model_name       = args.model_name\n",
    "\n",
    "\n",
    "run = Run.get_context()\n",
    "\n",
    "#Get associated AML workspace\n",
    "ws = run.experiment.workspace\n",
    "\n",
    "model = Model(ws, model_name)\n",
    "env = Environment.get(ws, environment_name)\n",
    "inference_config = InferenceConfig(entry_script='score.py', environment=env)\n",
    "\n",
    "#test_dataset = run.input_datasets['testing_data']\n",
    "\n",
    "print(deploy_file)\n",
    "with open(deploy_file, 'r+') as f:\n",
    "    result = f.read()\n",
    "\n",
    "print(result)\n",
    "print(type(result))\n",
    "\n",
    "if result == 'do not deploy model':\n",
    "    print('do not update the deployed model')\n",
    "    run.complete()\n",
    "\n",
    "else:\n",
    "    print('continue with deploying model...')        \n",
    "    # Deploy model\n",
    "    aci_config = AciWebservice.deploy_configuration(\n",
    "                cpu_cores = 1, \n",
    "                memory_gb = 2, \n",
    "                tags = {'model': 'diabetes remote training'},\n",
    "                auth_enabled=True,\n",
    "                enable_app_insights=True)\n",
    "\n",
    "    try:\n",
    "        service = Webservice(ws, name=service_name)\n",
    "        if service:\n",
    "            service.delete()\n",
    "    except WebserviceException as e:\n",
    "             print()\n",
    "\n",
    "    service = Model.deploy(ws, service_name, [model], inference_config, aci_config, overwrite=True)\n",
    "    service.wait_for_deployment(True)\n",
    "\n",
    "\n",
    "    # Output scoring url\n",
    "    print(service.scoring_uri)\n",
    "    with open(scoring_url_file, 'w+') as f:\n",
    "        f.write(service.scoring_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2956f270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting text_classificatin_example/score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/score.py\n",
    "\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "from azureml.core.model import Model\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#version 2\n",
    "# Called when the service is loaded\n",
    "def init():\n",
    "    global model\n",
    "    #Print statement for appinsights custom traces:\n",
    "    print (\"model initialized\" + time.strftime(\"%H:%M:%S\"))\n",
    "    # Get the path to the deployed model file and load it\n",
    "    path = os.path.join(Model.get_model_path('text_classification_001'))\n",
    "    \n",
    "    print(path)\n",
    "    model = joblib.load(path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Called when a request is received\n",
    "def run(raw_data):\n",
    "    try:\n",
    "        # Get the input data as a numpy array\n",
    "        #data = np.array(json.loads(raw_data)['data'])\n",
    "        # Get a prediction from the model\n",
    "        \n",
    "        json_data = json.loads(raw_data)\n",
    "        predictions = model.predict(json_data['data'])\n",
    "        print (\"Prediction created\" + time.strftime(\"%H:%M:%S\"))\n",
    "        print(predictions)\n",
    "        # Get the corresponding classname for each prediction (0 or 1)\n",
    "        #classnames = ['not-diabetic', 'diabetic']\n",
    "        predicted_classes = []\n",
    "        for prediction in predictions:\n",
    "            #val = int(prediction)\n",
    "            predicted_classes.append(prediction)\n",
    "        # Return the predictions as JSON\n",
    "        \n",
    "         # Log the input and output data to appinsights:\n",
    "        info = {\n",
    "            \"input\": raw_data,\n",
    "            \"output\": predicted_classes\n",
    "            }\n",
    "        print(json.dumps(info))\n",
    "        \n",
    "\n",
    "        return json.dumps(predicted_classes)\n",
    "    except Exception as e:\n",
    "        error = str(e)\n",
    "        print (error + time.strftime(\"%H:%M:%S\"))\n",
    "        return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e566da7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_file = PipelineData(name='scoring_file', datastore=default_ds)\n",
    "\n",
    "aci_service_name = 'text-classification'\n",
    "\n",
    "env_name = PipelineParameter(name='environment_name', default_value=registered_env_name)\n",
    "service_name = PipelineParameter(name='service_name', default_value=aci_service_name)\n",
    "scoring_file = PipelineData(name='scoring_file', datastore=default_ds)\n",
    "\n",
    "########################################################\n",
    "\n",
    "deploy_test = PythonScriptStep(\n",
    "    name='Deploy to ACI',\n",
    "    script_name='deploy.py',\n",
    "    arguments=[\n",
    "        '--scoring_file_output', scoring_file,\n",
    "        '--deploy_file', deploy_file,\n",
    "        '--environment_name', env_name,\n",
    "        '--service_name', service_name,\n",
    "        '--model_name', model_name\n",
    "        \n",
    "    ],\n",
    "    inputs=[\n",
    "        deploy_file.as_input('deploy_file'),\n",
    "            \n",
    "    ],\n",
    "    outputs=[scoring_file],\n",
    "    compute_target=pipeline_cluster,\n",
    "    source_directory='./' + experiment_folder,\n",
    "    allow_reuse=False,\n",
    "    runconfig=pipeline_run_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "892d148b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step Get Data and Create Model [518d9702][938ddd0b-93a6-46f3-9c1a-6d8ca4d256e9], (This step will run and generate new outputs)\n",
      "Created step Evaluate and Register Model [35a58ba4][d1fb2bc3-4568-4a41-bb5c-47aec09a5ee4], (This step will run and generate new outputs)\n",
      "Created step Deploy to ACI [e5be5eff][c55822f5-5932-4479-b6f7-23fc8290e4e6], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun 9d3073ad-0643-4446-81c0-d380dfa7a19a\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/9d3073ad-0643-4446-81c0-d380dfa7a19a?wsid=/subscriptions/b071bca8-0055-43f9-9ff8-ca9a144c2a6f/resourcegroups/aml-dev-rg/workspaces/aml-dev&tid=16b3c013-d300-468d-ac64-7eda0820b6d3\n",
      "PipelineRunId: 9d3073ad-0643-4446-81c0-d380dfa7a19a\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/9d3073ad-0643-4446-81c0-d380dfa7a19a?wsid=/subscriptions/b071bca8-0055-43f9-9ff8-ca9a144c2a6f/resourcegroups/aml-dev-rg/workspaces/aml-dev&tid=16b3c013-d300-468d-ac64-7eda0820b6d3\n",
      "PipelineRun Status: NotStarted\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: 904555b1-5f2f-45fa-b3c0-0110b277d80d\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/904555b1-5f2f-45fa-b3c0-0110b277d80d?wsid=/subscriptions/b071bca8-0055-43f9-9ff8-ca9a144c2a6f/resourcegroups/aml-dev-rg/workspaces/aml-dev&tid=16b3c013-d300-468d-ac64-7eda0820b6d3\n",
      "StepRun( Get Data and Create Model ) Status: NotStarted\n",
      "StepRun( Get Data and Create Model ) Status: Running\n",
      "\n",
      "StepRun(Get Data and Create Model) Execution Summary\n",
      "=====================================================\n",
      "StepRun( Get Data and Create Model ) Status: Finished\n",
      "{'runId': '904555b1-5f2f-45fa-b3c0-0110b277d80d', 'target': 'aml-cluster001', 'status': 'Completed', 'startTimeUtc': '2023-02-03T19:13:49.795867Z', 'endTimeUtc': '2023-02-03T19:14:20.113836Z', 'services': {}, 'properties': {'ContentSnapshotId': 'db93dbd0-4112-4b21-bc19-1a7fd3395991', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '938ddd0b-93a6-46f3-9c1a-6d8ca4d256e9', 'azureml.moduleName': 'Get Data and Create Model', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '518d9702', 'azureml.pipelinerunid': '9d3073ad-0643-4446-81c0-d380dfa7a19a', 'azureml.pipeline': '9d3073ad-0643-4446-81c0-d380dfa7a19a', 'azureml.pipelineComponent': 'masterescloud', '_azureml.ComputeTargetType': 'amlctrain', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [], 'outputDatasets': [{'identifier': {'savedId': '3909bcb7-a75f-4ea2-b035-5636fd6e91a8', 'registeredId': 'a1e4f36e-5abc-4647-b22f-b2190d0eb7db', 'registeredVersion': '13'}, 'outputType': 'RunOutput', 'outputDetails': {'outputName': 'training_data'}, 'dataset': {\n",
      "  \"source\": [\n",
      "    \"('workspaceblobstore', 'text_classification_001_training_data/904555b1-5f2f-45fa-b3c0-0110b277d80d')\"\n",
      "  ],\n",
      "  \"definition\": [\n",
      "    \"GetDatastoreFiles\",\n",
      "    \"ParseDelimited\",\n",
      "    \"DropColumns\"\n",
      "  ],\n",
      "  \"registration\": {\n",
      "    \"id\": \"3909bcb7-a75f-4ea2-b035-5636fd6e91a8\",\n",
      "    \"name\": \"text_classification_001_training_data\",\n",
      "    \"version\": 13,\n",
      "    \"workspace\": \"Workspace.create(name='aml-dev', subscription_id='b071bca8-0055-43f9-9ff8-ca9a144c2a6f', resource_group='aml-dev-rg')\"\n",
      "  }\n",
      "}}, {'identifier': {'savedId': 'f1638ce4-e7b4-4491-b0b5-1dad59786521', 'registeredId': 'd38831ce-2192-4969-a808-aefdec11c14d', 'registeredVersion': '13'}, 'outputType': 'RunOutput', 'outputDetails': {'outputName': 'testing_data'}, 'dataset': {\n",
      "  \"source\": [\n",
      "    \"('workspaceblobstore', 'text_classification_001_testing_data/904555b1-5f2f-45fa-b3c0-0110b277d80d')\"\n",
      "  ],\n",
      "  \"definition\": [\n",
      "    \"GetDatastoreFiles\",\n",
      "    \"ParseDelimited\",\n",
      "    \"DropColumns\"\n",
      "  ],\n",
      "  \"registration\": {\n",
      "    \"id\": \"f1638ce4-e7b4-4491-b0b5-1dad59786521\",\n",
      "    \"name\": \"text_classification_001_testing_data\",\n",
      "    \"version\": 13,\n",
      "    \"workspace\": \"Workspace.create(name='aml-dev', subscription_id='b071bca8-0055-43f9-9ff8-ca9a144c2a6f', resource_group='aml-dev-rg')\"\n",
      "  }\n",
      "}}], 'runDefinition': {'script': 'classifier_training.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--raw_file_location', '$AML_PARAMETER_raw_file_location', '--training_data', 'DatasetOutputConfig:training_data', '--testing_data', 'DatasetOutputConfig:testing_data', '--model_file', '$AZUREML_DATAREFERENCE_model_file', '--model_name', '$AML_PARAMETER_model_name'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'aml-cluster001', 'dataReferences': {'model_file': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/904555b1-5f2f-45fa-b3c0-0110b277d80d/model_file', 'pathOnCompute': None, 'overwrite': False}}, 'data': {}, 'outputData': {'training_data': {'outputLocation': {'dataset': None, 'dataPath': {'datastoreName': 'workspaceblobstore', 'relativePath': 'text_classification_001_training_data/{run-id}'}, 'uri': None, 'type': None}, 'mechanism': 'Mount', 'additionalOptions': {'pathOnCompute': None, 'registrationOptions': {'name': 'text_classification_001_training_data', 'description': None, 'tags': None, 'properties': {'azureml.pipelineRunId': '9d3073ad-0643-4446-81c0-d380dfa7a19a', 'azureml.pipelineRun.moduleNodeId': '518d9702', 'azureml.pipelineRun.outputPortName': 'training_data'}, 'datasetRegistrationOptions': {'additionalTransformation': '{\\n  \"blocks\": [\\n    {\\n      \"id\": \"59b94df6-cdff-4c16-93ee-f4f2002be4fb\",\\n      \"type\": \"Microsoft.DPrep.ParseDelimitedBlock\",\\n      \"arguments\": {\\n        \"columnHeadersMode\": 3,\\n        \"fileEncoding\": 0,\\n        \"handleQuotedLineBreaks\": false,\\n        \"preview\": false,\\n        \"separator\": \",\",\\n        \"skipRows\": 0,\\n        \"skipRowsMode\": 0\\n      },\\n      \"localData\": {},\\n      \"isEnabled\": true,\\n      \"name\": null,\\n      \"annotation\": null\\n    },\\n    {\\n      \"id\": \"4fb31466-d644-4fd9-8d58-796f64f8946e\",\\n      \"type\": \"Microsoft.DPrep.DropColumnsBlock\",\\n      \"arguments\": {\\n        \"columns\": {\\n          \"type\": 0,\\n          \"details\": {\\n            \"selectedColumns\": [\\n              \"Path\"\\n            ]\\n          }\\n        }\\n      },\\n      \"localData\": {},\\n      \"isEnabled\": true,\\n      \"name\": null,\\n      \"annotation\": null\\n    }\\n  ],\\n  \"inspectors\": [],\\n  \"meta\": {\\n    \"steps_added\": \"2\"\\n  }\\n}'}}, 'uploadOptions': {'overwrite': False, 'sourceGlobs': {'globPatterns': None}}, 'mountOptions': None}, 'environmentVariableName': None}, 'testing_data': {'outputLocation': {'dataset': None, 'dataPath': {'datastoreName': 'workspaceblobstore', 'relativePath': 'text_classification_001_testing_data/{run-id}'}, 'uri': None, 'type': None}, 'mechanism': 'Mount', 'additionalOptions': {'pathOnCompute': None, 'registrationOptions': {'name': 'text_classification_001_testing_data', 'description': None, 'tags': None, 'properties': {'azureml.pipelineRunId': '9d3073ad-0643-4446-81c0-d380dfa7a19a', 'azureml.pipelineRun.moduleNodeId': '518d9702', 'azureml.pipelineRun.outputPortName': 'testing_data'}, 'datasetRegistrationOptions': {'additionalTransformation': '{\\n  \"blocks\": [\\n    {\\n      \"id\": \"28f3aef5-bc2c-4928-babd-1843563629e0\",\\n      \"type\": \"Microsoft.DPrep.ParseDelimitedBlock\",\\n      \"arguments\": {\\n        \"columnHeadersMode\": 3,\\n        \"fileEncoding\": 0,\\n        \"handleQuotedLineBreaks\": false,\\n        \"preview\": false,\\n        \"separator\": \",\",\\n        \"skipRows\": 0,\\n        \"skipRowsMode\": 0\\n      },\\n      \"localData\": {},\\n      \"isEnabled\": true,\\n      \"name\": null,\\n      \"annotation\": null\\n    },\\n    {\\n      \"id\": \"52f20067-5b11-4a24-82f7-1ddced52df5f\",\\n      \"type\": \"Microsoft.DPrep.DropColumnsBlock\",\\n      \"arguments\": {\\n        \"columns\": {\\n          \"type\": 0,\\n          \"details\": {\\n            \"selectedColumns\": [\\n              \"Path\"\\n            ]\\n          }\\n        }\\n      },\\n      \"localData\": {},\\n      \"isEnabled\": true,\\n      \"name\": null,\\n      \"annotation\": null\\n    }\\n  ],\\n  \"inspectors\": [],\\n  \"meta\": {\\n    \"steps_added\": \"2\"\\n  }\\n}'}}, 'uploadOptions': {'overwrite': False, 'sourceGlobs': {'globPatterns': None}}, 'mountOptions': None}, 'environmentVariableName': None}}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'instanceTypes': [], 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'text-classificiation-env', 'version': '1', 'assetId': 'azureml://locations/eastus2/workspaces/9634b616-29cb-4345-ae22-4be4e4bfe009/environments/text-classificiation-env/versions/1', 'autoRebuild': True, 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'name': 'textclassification_env', 'dependencies': ['python=3.8.5', 'scikit-learn', 'ipykernel', 'matplotlib', 'pandas', 'pip', {'pip': ['azureml-defaults', 'numpy', 'joblib', 'sklearn']}]}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20221101.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': 'D2', 'imageVersion': 'pytorch-1.7.0', 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'sshPublicKeys': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard', 'userAlias': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {'AML_PARAMETER_raw_file_location': 'spam-data/spamformodel.csv', 'AML_PARAMETER_model_name': 'text_classification_001'}, 'applicationEndpoints': {}, 'parameters': []}, 'logFiles': {'logs/azureml/dataprep/0/backgroundProcess.log': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.904555b1-5f2f-45fa-b3c0-0110b277d80d/logs/azureml/dataprep/0/backgroundProcess.log?sv=2019-07-07&sr=b&sig=hmhRKl6tdtA94SC1Dr5qzwtNfMqkNUoWNfqncyfF%2FJI%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-03T18%3A14%3A47Z&ske=2023-02-05T02%3A24%3A47Z&sks=b&skv=2019-07-07&st=2023-02-03T19%3A04%3A14Z&se=2023-02-04T03%3A14%3A14Z&sp=r', 'logs/azureml/dataprep/0/backgroundProcess_Telemetry.log': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.904555b1-5f2f-45fa-b3c0-0110b277d80d/logs/azureml/dataprep/0/backgroundProcess_Telemetry.log?sv=2019-07-07&sr=b&sig=onvbpDqXgTqeEce3hhyiCfunvjWVvUR%2FT2X879pPT%2FU%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-03T18%3A14%3A47Z&ske=2023-02-05T02%3A24%3A47Z&sks=b&skv=2019-07-07&st=2023-02-03T19%3A04%3A14Z&se=2023-02-04T03%3A14%3A14Z&sp=r', 'logs/azureml/dataprep/0/rslex.log.2023-02-03-19': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.904555b1-5f2f-45fa-b3c0-0110b277d80d/logs/azureml/dataprep/0/rslex.log.2023-02-03-19?sv=2019-07-07&sr=b&sig=mNvFCEVJgumBKUpppZs3nqazfxOpkpaKjU0W69Uz7to%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-03T18%3A14%3A47Z&ske=2023-02-05T02%3A24%3A47Z&sks=b&skv=2019-07-07&st=2023-02-03T19%3A04%3A14Z&se=2023-02-04T03%3A14%3A14Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.904555b1-5f2f-45fa-b3c0-0110b277d80d/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=mcjfutK9Cu7v%2BVcTwvM%2F7gtQiu5vKHjK2cyPh3GSXCY%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-03T18%3A14%3A47Z&ske=2023-02-05T02%3A24%3A47Z&sks=b&skv=2019-07-07&st=2023-02-03T19%3A04%3A14Z&se=2023-02-04T03%3A14%3A14Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.904555b1-5f2f-45fa-b3c0-0110b277d80d/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=ECfqAMOND%2FPRN7hSqWiC4hlR7HH4A%2FlzjfCwoWrwhA4%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-03T18%3A14%3A47Z&ske=2023-02-05T02%3A24%3A47Z&sks=b&skv=2019-07-07&st=2023-02-03T19%3A04%3A14Z&se=2023-02-04T03%3A14%3A14Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.904555b1-5f2f-45fa-b3c0-0110b277d80d/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=0jbgEKsfR4RAX%2FcjBBEdTvNIWNNLLbKfpt8LDCv0Pm0%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-03T18%3A14%3A47Z&ske=2023-02-05T02%3A24%3A47Z&sks=b&skv=2019-07-07&st=2023-02-03T19%3A04%3A14Z&se=2023-02-04T03%3A14%3A14Z&sp=r', 'user_logs/std_log.txt': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.904555b1-5f2f-45fa-b3c0-0110b277d80d/user_logs/std_log.txt?sv=2019-07-07&sr=b&sig=XWR21KKbD5Mz0N4wh%2F0xbK5%2BiE9SW3H8tM4qhgO%2Fzv0%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-03T18%3A14%3A47Z&ske=2023-02-05T02%3A24%3A47Z&sks=b&skv=2019-07-07&st=2023-02-03T19%3A04%3A22Z&se=2023-02-04T03%3A14%3A22Z&sp=r', 'system_logs/cs_capability/cs-capability.log': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.904555b1-5f2f-45fa-b3c0-0110b277d80d/system_logs/cs_capability/cs-capability.log?sv=2019-07-07&sr=b&sig=7HY7N%2B4n9hWnl0SgRuwU7LbUMlGyn1Hd%2BduUelLiq7U%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-03T18%3A14%3A47Z&ske=2023-02-05T02%3A24%3A47Z&sks=b&skv=2019-07-07&st=2023-02-03T19%3A04%3A22Z&se=2023-02-04T03%3A14%3A22Z&sp=r', 'system_logs/data_capability/data-capability.log': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.904555b1-5f2f-45fa-b3c0-0110b277d80d/system_logs/data_capability/data-capability.log?sv=2019-07-07&sr=b&sig=YTq49d%2FLM9ATJOfnYoBzgRvSLHQVjcJuGHrO0oPjuxk%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-03T18%3A14%3A47Z&ske=2023-02-05T02%3A24%3A47Z&sks=b&skv=2019-07-07&st=2023-02-03T19%3A04%3A22Z&se=2023-02-04T03%3A14%3A22Z&sp=r', 'system_logs/data_capability/rslex.log.2023-02-03-19': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.904555b1-5f2f-45fa-b3c0-0110b277d80d/system_logs/data_capability/rslex.log.2023-02-03-19?sv=2019-07-07&sr=b&sig=19rvA7nw0qsgoMFmoAnWvGcFRcE5LYzYzdELEU2lobc%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-03T18%3A14%3A47Z&ske=2023-02-05T02%3A24%3A47Z&sks=b&skv=2019-07-07&st=2023-02-03T19%3A04%3A22Z&se=2023-02-04T03%3A14%3A22Z&sp=r', 'system_logs/hosttools_capability/hosttools-capability.log': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.904555b1-5f2f-45fa-b3c0-0110b277d80d/system_logs/hosttools_capability/hosttools-capability.log?sv=2019-07-07&sr=b&sig=lA5YntoQEeNhl0vJITAkYlxcyhxhRnZlpw%2FfkjLB0tE%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-03T18%3A14%3A47Z&ske=2023-02-05T02%3A24%3A47Z&sks=b&skv=2019-07-07&st=2023-02-03T19%3A04%3A22Z&se=2023-02-04T03%3A14%3A22Z&sp=r', 'system_logs/lifecycler/execution-wrapper.log': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.904555b1-5f2f-45fa-b3c0-0110b277d80d/system_logs/lifecycler/execution-wrapper.log?sv=2019-07-07&sr=b&sig=vtgWz2tX96IW42qL59Y5GAGIFEztl03rjtrAEbAWjrA%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-03T18%3A14%3A47Z&ske=2023-02-05T02%3A24%3A47Z&sks=b&skv=2019-07-07&st=2023-02-03T19%3A04%3A22Z&se=2023-02-04T03%3A14%3A22Z&sp=r', 'system_logs/lifecycler/lifecycler.log': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.904555b1-5f2f-45fa-b3c0-0110b277d80d/system_logs/lifecycler/lifecycler.log?sv=2019-07-07&sr=b&sig=vuBHJb2%2BWRBT57G1YmKzKA9tpnd4SXnwfVzlIZKk5VU%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-03T18%3A14%3A47Z&ske=2023-02-05T02%3A24%3A47Z&sks=b&skv=2019-07-07&st=2023-02-03T19%3A04%3A22Z&se=2023-02-04T03%3A14%3A22Z&sp=r', 'system_logs/metrics_capability/metrics-capability.log': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.904555b1-5f2f-45fa-b3c0-0110b277d80d/system_logs/metrics_capability/metrics-capability.log?sv=2019-07-07&sr=b&sig=7QQVM6LheWZKDqK4IvkUzFQSBNXE42mD3BFIcY6mPew%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-03T18%3A14%3A47Z&ske=2023-02-05T02%3A24%3A47Z&sks=b&skv=2019-07-07&st=2023-02-03T19%3A04%3A22Z&se=2023-02-04T03%3A14%3A22Z&sp=r', 'system_logs/snapshot_capability/snapshot-capability.log': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.904555b1-5f2f-45fa-b3c0-0110b277d80d/system_logs/snapshot_capability/snapshot-capability.log?sv=2019-07-07&sr=b&sig=URYRdDBNxFwduGzZdDMugP98UwGEh%2FOccywPMTaJgE8%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-03T18%3A14%3A47Z&ske=2023-02-05T02%3A24%3A47Z&sks=b&skv=2019-07-07&st=2023-02-03T19%3A04%3A22Z&se=2023-02-04T03%3A14%3A22Z&sp=r'}, 'submittedBy': 'e51aa7c8-2975-4062-85fe-af95c0b8e461'}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "StepRunId: 53fbe841-5912-4b95-aa30-6ca137954be7\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/53fbe841-5912-4b95-aa30-6ca137954be7?wsid=/subscriptions/b071bca8-0055-43f9-9ff8-ca9a144c2a6f/resourcegroups/aml-dev-rg/workspaces/aml-dev&tid=16b3c013-d300-468d-ac64-7eda0820b6d3\n",
      "StepRun( Evaluate and Register Model ) Status: NotStarted\n",
      "StepRun( Evaluate and Register Model ) Status: Running\n",
      "\n",
      "StepRun(Evaluate and Register Model) Execution Summary\n",
      "=======================================================\n",
      "StepRun( Evaluate and Register Model ) Status: Finished\n",
      "{'runId': '53fbe841-5912-4b95-aa30-6ca137954be7', 'target': 'aml-cluster001', 'status': 'Completed', 'startTimeUtc': '2023-02-03T19:14:26.450309Z', 'endTimeUtc': '2023-02-03T19:14:46.61759Z', 'services': {}, 'properties': {'ContentSnapshotId': 'db93dbd0-4112-4b21-bc19-1a7fd3395991', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': 'd1fb2bc3-4568-4a41-bb5c-47aec09a5ee4', 'azureml.moduleName': 'Evaluate and Register Model', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '35a58ba4', 'azureml.pipelinerunid': '9d3073ad-0643-4446-81c0-d380dfa7a19a', 'azureml.pipeline': '9d3073ad-0643-4446-81c0-d380dfa7a19a', 'azureml.pipelineComponent': 'masterescloud', '_azureml.ComputeTargetType': 'amlctrain', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [{'dataset': {'id': 'fb01f10e-2aa0-43c2-9200-7c3108c0063a'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'training_data', 'mechanism': 'Direct'}}, {'dataset': {'id': '4c493dd5-f832-462e-a5d5-128ee8e5e5f5'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'testing_data', 'mechanism': 'Direct'}}], 'outputDatasets': [], 'runDefinition': {'script': 'eval.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--model_name', '$AML_PARAMETER_model_name', '--model_file', '$AZUREML_DATAREFERENCE_model_file', '--model_desc', '$AML_PARAMETER_model_desc', '--deploy_file', '$AZUREML_DATAREFERENCE_deploy_file'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'aml-cluster001', 'dataReferences': {'model_file': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/904555b1-5f2f-45fa-b3c0-0110b277d80d/model_file', 'pathOnCompute': None, 'overwrite': False}, 'deploy_file': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/53fbe841-5912-4b95-aa30-6ca137954be7/deploy_file', 'pathOnCompute': None, 'overwrite': False}}, 'data': {'training_data': {'dataLocation': {'dataset': {'id': 'fb01f10e-2aa0-43c2-9200-7c3108c0063a', 'name': None, 'version': None}, 'dataPath': None, 'uri': None, 'type': None}, 'mechanism': 'Direct', 'environmentVariableName': 'training_data', 'pathOnCompute': None, 'overwrite': False, 'options': None}, 'testing_data': {'dataLocation': {'dataset': {'id': '4c493dd5-f832-462e-a5d5-128ee8e5e5f5', 'name': None, 'version': None}, 'dataPath': None, 'uri': None, 'type': None}, 'mechanism': 'Direct', 'environmentVariableName': 'testing_data', 'pathOnCompute': None, 'overwrite': False, 'options': None}}, 'outputData': {}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'instanceTypes': [], 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'text-classificiation-env', 'version': '1', 'assetId': 'azureml://locations/eastus2/workspaces/9634b616-29cb-4345-ae22-4be4e4bfe009/environments/text-classificiation-env/versions/1', 'autoRebuild': True, 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'name': 'textclassification_env', 'dependencies': ['python=3.8.5', 'scikit-learn', 'ipykernel', 'matplotlib', 'pandas', 'pip', {'pip': ['azureml-defaults', 'numpy', 'joblib', 'sklearn']}]}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20221101.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': 'D2', 'imageVersion': 'pytorch-1.7.0', 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'sshPublicKeys': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard', 'userAlias': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {'AML_PARAMETER_model_name': 'text_classification_001', 'AML_PARAMETER_model_desc': 'text_classification_001 description'}, 'applicationEndpoints': {}, 'parameters': []}, 'logFiles': {'logs/azureml/dataprep/0/backgroundProcess.log': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.53fbe841-5912-4b95-aa30-6ca137954be7/logs/azureml/dataprep/0/backgroundProcess.log?sv=2019-07-07&sr=b&sig=%2FzEDf%2FF%2BBpOAuABUK2%2BBgk6qFwHerge7whJR2eNxO%2B4%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-03T18%3A14%3A47Z&ske=2023-02-05T02%3A24%3A47Z&sks=b&skv=2019-07-07&st=2023-02-03T19%3A04%3A41Z&se=2023-02-04T03%3A14%3A41Z&sp=r', 'logs/azureml/dataprep/0/backgroundProcess_Telemetry.log': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.53fbe841-5912-4b95-aa30-6ca137954be7/logs/azureml/dataprep/0/backgroundProcess_Telemetry.log?sv=2019-07-07&sr=b&sig=V1k7hVSWPqs2khwFpnyrp%2FgL9QrkAsyt%2B%2BJsYnrP5uQ%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-03T18%3A14%3A47Z&ske=2023-02-05T02%3A24%3A47Z&sks=b&skv=2019-07-07&st=2023-02-03T19%3A04%3A41Z&se=2023-02-04T03%3A14%3A41Z&sp=r', 'logs/azureml/dataprep/0/rslex.log.2023-02-03-19': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.53fbe841-5912-4b95-aa30-6ca137954be7/logs/azureml/dataprep/0/rslex.log.2023-02-03-19?sv=2019-07-07&sr=b&sig=C0xzQfm29w%2FhRvgZ%2BVa3CulS2kdezZDrhZ8ihexMDv0%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-03T18%3A14%3A47Z&ske=2023-02-05T02%3A24%3A47Z&sks=b&skv=2019-07-07&st=2023-02-03T19%3A04%3A41Z&se=2023-02-04T03%3A14%3A41Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.53fbe841-5912-4b95-aa30-6ca137954be7/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=WcmRUqEf2rnPLobYqrDA2aiDZDimn9Bk1taDTQFCE0E%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-03T18%3A14%3A47Z&ske=2023-02-05T02%3A24%3A47Z&sks=b&skv=2019-07-07&st=2023-02-03T19%3A04%3A41Z&se=2023-02-04T03%3A14%3A41Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.53fbe841-5912-4b95-aa30-6ca137954be7/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=4GqDgM1MMFWZ8%2Bm56tMPEpLE3b06fl7jSdNkAa94IB0%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-03T18%3A14%3A47Z&ske=2023-02-05T02%3A24%3A47Z&sks=b&skv=2019-07-07&st=2023-02-03T19%3A04%3A41Z&se=2023-02-04T03%3A14%3A41Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.53fbe841-5912-4b95-aa30-6ca137954be7/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=GbjuYFwcUKak0MJj3HyH4TsfVyHM%2FLbvNCQwQSEV4Tg%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-03T18%3A14%3A47Z&ske=2023-02-05T02%3A24%3A47Z&sks=b&skv=2019-07-07&st=2023-02-03T19%3A04%3A41Z&se=2023-02-04T03%3A14%3A41Z&sp=r', 'user_logs/std_log.txt': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.53fbe841-5912-4b95-aa30-6ca137954be7/user_logs/std_log.txt?sv=2019-07-07&sr=b&sig=dD8kSz3L%2F%2FLUXQT%2BM7UPWnT0B%2FgFs64XjyPR6gRLnF8%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-03T18%3A14%3A47Z&ske=2023-02-05T02%3A24%3A47Z&sks=b&skv=2019-07-07&st=2023-02-03T19%3A04%3A47Z&se=2023-02-04T03%3A14%3A47Z&sp=r', 'system_logs/cs_capability/cs-capability.log': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.53fbe841-5912-4b95-aa30-6ca137954be7/system_logs/cs_capability/cs-capability.log?sv=2019-07-07&sr=b&sig=IZv2OgWrNHKXLY4i86JWxPvkUHBuvOHOj4bMXLzXNF4%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-03T18%3A14%3A47Z&ske=2023-02-05T02%3A24%3A47Z&sks=b&skv=2019-07-07&st=2023-02-03T19%3A04%3A47Z&se=2023-02-04T03%3A14%3A47Z&sp=r', 'system_logs/data_capability/data-capability.log': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.53fbe841-5912-4b95-aa30-6ca137954be7/system_logs/data_capability/data-capability.log?sv=2019-07-07&sr=b&sig=ZxAgrrZrORtBSM%2BaJMIbhpna6OsEk4vpsryvNE1RxEE%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-03T18%3A14%3A47Z&ske=2023-02-05T02%3A24%3A47Z&sks=b&skv=2019-07-07&st=2023-02-03T19%3A04%3A47Z&se=2023-02-04T03%3A14%3A47Z&sp=r', 'system_logs/data_capability/rslex.log.2023-02-03-19': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.53fbe841-5912-4b95-aa30-6ca137954be7/system_logs/data_capability/rslex.log.2023-02-03-19?sv=2019-07-07&sr=b&sig=4OKLb3cCJX%2FqdUW9QoGqmOI4TkPddUZXEcBFA%2BwBm1U%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-03T18%3A14%3A47Z&ske=2023-02-05T02%3A24%3A47Z&sks=b&skv=2019-07-07&st=2023-02-03T19%3A04%3A47Z&se=2023-02-04T03%3A14%3A47Z&sp=r', 'system_logs/hosttools_capability/hosttools-capability.log': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.53fbe841-5912-4b95-aa30-6ca137954be7/system_logs/hosttools_capability/hosttools-capability.log?sv=2019-07-07&sr=b&sig=gK13f%2BHT8boGw0wfFW2yZqArINJAUTL03v850jFKiBY%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-03T18%3A14%3A47Z&ske=2023-02-05T02%3A24%3A47Z&sks=b&skv=2019-07-07&st=2023-02-03T19%3A04%3A47Z&se=2023-02-04T03%3A14%3A47Z&sp=r', 'system_logs/lifecycler/execution-wrapper.log': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.53fbe841-5912-4b95-aa30-6ca137954be7/system_logs/lifecycler/execution-wrapper.log?sv=2019-07-07&sr=b&sig=zI193eLH51Pxj%2BrG3Te1NJF5hs%2BjgjRU3Qj3sQ2EHlk%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-03T18%3A14%3A47Z&ske=2023-02-05T02%3A24%3A47Z&sks=b&skv=2019-07-07&st=2023-02-03T19%3A04%3A47Z&se=2023-02-04T03%3A14%3A47Z&sp=r', 'system_logs/lifecycler/lifecycler.log': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.53fbe841-5912-4b95-aa30-6ca137954be7/system_logs/lifecycler/lifecycler.log?sv=2019-07-07&sr=b&sig=V0ywuY7kqIpkONVjztWuuVBCqiQJ9SSzmT%2FhAoVuNGI%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-03T18%3A14%3A47Z&ske=2023-02-05T02%3A24%3A47Z&sks=b&skv=2019-07-07&st=2023-02-03T19%3A04%3A47Z&se=2023-02-04T03%3A14%3A47Z&sp=r', 'system_logs/metrics_capability/metrics-capability.log': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.53fbe841-5912-4b95-aa30-6ca137954be7/system_logs/metrics_capability/metrics-capability.log?sv=2019-07-07&sr=b&sig=XPlLHpDnAHWRPjifY0GIPZs5bXcD5DSDtDzuYLWdvZM%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-03T18%3A14%3A47Z&ske=2023-02-05T02%3A24%3A47Z&sks=b&skv=2019-07-07&st=2023-02-03T19%3A04%3A47Z&se=2023-02-04T03%3A14%3A47Z&sp=r', 'system_logs/snapshot_capability/snapshot-capability.log': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.53fbe841-5912-4b95-aa30-6ca137954be7/system_logs/snapshot_capability/snapshot-capability.log?sv=2019-07-07&sr=b&sig=C3GTmsaFv3q2TawBaZzhBR1W8dvacELAiJ7r6oN%2FCMM%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-03T18%3A14%3A47Z&ske=2023-02-05T02%3A24%3A47Z&sks=b&skv=2019-07-07&st=2023-02-03T19%3A04%3A47Z&se=2023-02-04T03%3A14%3A47Z&sp=r'}, 'submittedBy': 'e51aa7c8-2975-4062-85fe-af95c0b8e461'}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "StepRunId: 8df012b9-192d-463c-8ce1-4f9239bfff9d\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/8df012b9-192d-463c-8ce1-4f9239bfff9d?wsid=/subscriptions/b071bca8-0055-43f9-9ff8-ca9a144c2a6f/resourcegroups/aml-dev-rg/workspaces/aml-dev&tid=16b3c013-d300-468d-ac64-7eda0820b6d3\n",
      "StepRun( Deploy to ACI ) Status: NotStarted\n",
      "\n",
      "StepRun(Deploy to ACI) Execution Summary\n",
      "=========================================\n",
      "StepRun( Deploy to ACI ) Status: Finished\n",
      "{'runId': '8df012b9-192d-463c-8ce1-4f9239bfff9d', 'target': 'aml-cluster001', 'status': 'Completed', 'startTimeUtc': '2023-02-03T19:14:55.005198Z', 'endTimeUtc': '2023-02-03T19:15:07.479471Z', 'services': {}, 'properties': {'ContentSnapshotId': 'db93dbd0-4112-4b21-bc19-1a7fd3395991', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': 'c55822f5-5932-4479-b6f7-23fc8290e4e6', 'azureml.moduleName': 'Deploy to ACI', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': 'e5be5eff', 'azureml.pipelinerunid': '9d3073ad-0643-4446-81c0-d380dfa7a19a', 'azureml.pipeline': '9d3073ad-0643-4446-81c0-d380dfa7a19a', 'azureml.pipelineComponent': 'masterescloud', '_azureml.ComputeTargetType': 'amlctrain', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [], 'outputDatasets': [], 'runDefinition': {'script': 'deploy.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--scoring_file_output', '$AZUREML_DATAREFERENCE_scoring_file', '--deploy_file', '$AZUREML_DATAREFERENCE_deploy_file', '--environment_name', '$AML_PARAMETER_environment_name', '--service_name', '$AML_PARAMETER_service_name', '--model_name', '$AML_PARAMETER_model_name'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'aml-cluster001', 'dataReferences': {'deploy_file': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/53fbe841-5912-4b95-aa30-6ca137954be7/deploy_file', 'pathOnCompute': None, 'overwrite': False}, 'scoring_file': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/8df012b9-192d-463c-8ce1-4f9239bfff9d/scoring_file', 'pathOnCompute': None, 'overwrite': False}}, 'data': {}, 'outputData': {}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'instanceTypes': [], 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'text-classificiation-env', 'version': '1', 'assetId': 'azureml://locations/eastus2/workspaces/9634b616-29cb-4345-ae22-4be4e4bfe009/environments/text-classificiation-env/versions/1', 'autoRebuild': True, 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'name': 'textclassification_env', 'dependencies': ['python=3.8.5', 'scikit-learn', 'ipykernel', 'matplotlib', 'pandas', 'pip', {'pip': ['azureml-defaults', 'numpy', 'joblib', 'sklearn']}]}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20221101.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': 'D2', 'imageVersion': 'pytorch-1.7.0', 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'sshPublicKeys': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard', 'userAlias': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {'AML_PARAMETER_environment_name': 'text-classificiation-env', 'AML_PARAMETER_service_name': 'text-classification', 'AML_PARAMETER_model_name': 'text_classification_001'}, 'applicationEndpoints': {}, 'parameters': []}, 'logFiles': {'logs/azureml/executionlogs.txt': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.8df012b9-192d-463c-8ce1-4f9239bfff9d/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=Z6IYGiCNrIO33ziIpVnvWVbVlDrNqiA6jauSZgOebHA%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-03T18%3A14%3A47Z&ske=2023-02-05T02%3A24%3A47Z&sks=b&skv=2019-07-07&st=2023-02-03T19%3A04%3A52Z&se=2023-02-04T03%3A14%3A52Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.8df012b9-192d-463c-8ce1-4f9239bfff9d/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=tSn1szG6ZBoU3xDNryWkCz8xlZvrhiDX41ignDRjpU0%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-03T18%3A14%3A47Z&ske=2023-02-05T02%3A24%3A47Z&sks=b&skv=2019-07-07&st=2023-02-03T19%3A04%3A52Z&se=2023-02-04T03%3A14%3A52Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.8df012b9-192d-463c-8ce1-4f9239bfff9d/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=2Utgd%2F7xUNulQC021eyqlcChF7kVocQusLKRS%2F8laBc%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-03T18%3A14%3A47Z&ske=2023-02-05T02%3A24%3A47Z&sks=b&skv=2019-07-07&st=2023-02-03T19%3A04%3A52Z&se=2023-02-04T03%3A14%3A52Z&sp=r', 'user_logs/std_log.txt': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.8df012b9-192d-463c-8ce1-4f9239bfff9d/user_logs/std_log.txt?sv=2019-07-07&sr=b&sig=7%2BxM7txsKBO0bI%2BvqzJQ%2FlDEYOwtBkCRC9MMwryC9HI%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-03T18%3A14%3A47Z&ske=2023-02-05T02%3A24%3A47Z&sks=b&skv=2019-07-07&st=2023-02-03T19%3A05%3A08Z&se=2023-02-04T03%3A15%3A08Z&sp=r', 'system_logs/cs_capability/cs-capability.log': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.8df012b9-192d-463c-8ce1-4f9239bfff9d/system_logs/cs_capability/cs-capability.log?sv=2019-07-07&sr=b&sig=qitoBekJ%2BZU8bdJLPNHaF8LJ40zmuJP2efoBDUBy4xU%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-03T18%3A14%3A47Z&ske=2023-02-05T02%3A24%3A47Z&sks=b&skv=2019-07-07&st=2023-02-03T19%3A05%3A08Z&se=2023-02-04T03%3A15%3A08Z&sp=r', 'system_logs/data_capability/data-capability.log': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.8df012b9-192d-463c-8ce1-4f9239bfff9d/system_logs/data_capability/data-capability.log?sv=2019-07-07&sr=b&sig=Kob32nlWZeXd98%2BfA3OqXGZaxbGssF8TM8gSonTBJe8%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-03T18%3A14%3A47Z&ske=2023-02-05T02%3A24%3A47Z&sks=b&skv=2019-07-07&st=2023-02-03T19%3A05%3A08Z&se=2023-02-04T03%3A15%3A08Z&sp=r', 'system_logs/data_capability/rslex.log.2023-02-03-19': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.8df012b9-192d-463c-8ce1-4f9239bfff9d/system_logs/data_capability/rslex.log.2023-02-03-19?sv=2019-07-07&sr=b&sig=1HuECNvfOwLGeyB0kBiCJC5MjpdOnU5qGGsgK7VA%2FeA%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-03T18%3A14%3A47Z&ske=2023-02-05T02%3A24%3A47Z&sks=b&skv=2019-07-07&st=2023-02-03T19%3A05%3A08Z&se=2023-02-04T03%3A15%3A08Z&sp=r', 'system_logs/hosttools_capability/hosttools-capability.log': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.8df012b9-192d-463c-8ce1-4f9239bfff9d/system_logs/hosttools_capability/hosttools-capability.log?sv=2019-07-07&sr=b&sig=%2FbjTl5oXAshoNP5nfVmjxSJAuFj4PM2pPJiKvCvVuak%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-03T18%3A14%3A47Z&ske=2023-02-05T02%3A24%3A47Z&sks=b&skv=2019-07-07&st=2023-02-03T19%3A05%3A08Z&se=2023-02-04T03%3A15%3A08Z&sp=r', 'system_logs/lifecycler/execution-wrapper.log': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.8df012b9-192d-463c-8ce1-4f9239bfff9d/system_logs/lifecycler/execution-wrapper.log?sv=2019-07-07&sr=b&sig=%2Fj8mvoHCEUZt13qbmKZbc%2FsPC3460sPQiX%2BNKc%2FvpI8%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-03T18%3A14%3A47Z&ske=2023-02-05T02%3A24%3A47Z&sks=b&skv=2019-07-07&st=2023-02-03T19%3A05%3A08Z&se=2023-02-04T03%3A15%3A08Z&sp=r', 'system_logs/lifecycler/lifecycler.log': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.8df012b9-192d-463c-8ce1-4f9239bfff9d/system_logs/lifecycler/lifecycler.log?sv=2019-07-07&sr=b&sig=mPLDDpyOcNuByGzBLons4iW9ngTKR8OF8%2BoLLC0Dges%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-03T18%3A14%3A47Z&ske=2023-02-05T02%3A24%3A47Z&sks=b&skv=2019-07-07&st=2023-02-03T19%3A05%3A08Z&se=2023-02-04T03%3A15%3A08Z&sp=r', 'system_logs/metrics_capability/metrics-capability.log': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.8df012b9-192d-463c-8ce1-4f9239bfff9d/system_logs/metrics_capability/metrics-capability.log?sv=2019-07-07&sr=b&sig=Zvq%2F8ZqEqjUkK4RzM74L3E%2FbYZ%2Bx5fgTrlDIqeO0ylU%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-03T18%3A14%3A47Z&ske=2023-02-05T02%3A24%3A47Z&sks=b&skv=2019-07-07&st=2023-02-03T19%3A05%3A08Z&se=2023-02-04T03%3A15%3A08Z&sp=r', 'system_logs/snapshot_capability/snapshot-capability.log': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.8df012b9-192d-463c-8ce1-4f9239bfff9d/system_logs/snapshot_capability/snapshot-capability.log?sv=2019-07-07&sr=b&sig=q7B9k4FsHwFOWUvLukkFn0ec4X05bfAZHnbuLeISFLg%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-03T18%3A14%3A47Z&ske=2023-02-05T02%3A24%3A47Z&sks=b&skv=2019-07-07&st=2023-02-03T19%3A05%3A08Z&se=2023-02-04T03%3A15%3A08Z&sp=r'}, 'submittedBy': 'e51aa7c8-2975-4062-85fe-af95c0b8e461'}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': '9d3073ad-0643-4446-81c0-d380dfa7a19a', 'status': 'Completed', 'startTimeUtc': '2023-02-03T19:13:43.723781Z', 'endTimeUtc': '2023-02-03T19:15:08.132494Z', 'services': {}, 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{\"raw_file_location\":\"spam-data/spamformodel.csv\",\"model_name\":\"text_classification_001\",\"model_desc\":\"text_classification_001 description\",\"environment_name\":\"text-classificiation-env\",\"service_name\":\"text-classification\"}', 'azureml.continue_on_step_failure': 'False', 'azureml.continue_on_failed_optional_input': 'True', 'azureml.pipelineComponent': 'pipelinerun', 'azureml.pipelines.stages': '{\"Initialization\":null,\"Execution\":{\"StartTime\":\"2023-02-03T19:13:43.9830524+00:00\",\"EndTime\":\"2023-02-03T19:15:08.0503555+00:00\",\"Status\":\"Finished\"}}'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.9d3073ad-0643-4446-81c0-d380dfa7a19a/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=%2BWjSh6JMTk5oQK4M2IhynwUgrSpZV428VfW6v%2FKvz%2BE%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-03T18%3A14%3A47Z&ske=2023-02-05T02%3A24%3A47Z&sks=b&skv=2019-07-07&st=2023-02-03T19%3A04%3A07Z&se=2023-02-04T03%3A14%3A07Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.9d3073ad-0643-4446-81c0-d380dfa7a19a/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=1%2Fh%2FA3%2BRkRv9gdJmdl6rTA%2BY%2F6NAcI68XzaAojVkm5U%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-03T18%3A14%3A47Z&ske=2023-02-05T02%3A24%3A47Z&sks=b&skv=2019-07-07&st=2023-02-03T19%3A04%3A07Z&se=2023-02-04T03%3A14%3A07Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.9d3073ad-0643-4446-81c0-d380dfa7a19a/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=5buGU7L4zgtIQ6zGXQBJzJNDvOmzEPdvfG1%2F24sfFOM%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-03T18%3A14%3A47Z&ske=2023-02-05T02%3A24%3A47Z&sks=b&skv=2019-07-07&st=2023-02-03T19%3A04%3A07Z&se=2023-02-04T03%3A14%3A07Z&sp=r'}, 'submittedBy': 'e51aa7c8-2975-4062-85fe-af95c0b8e461'}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create Pipeline Steps\n",
    "pipeline = Pipeline(workspace=ws, steps=[train_model_step, evaluate_and_register_step, deploy_test])\n",
    "if run_by_notebook:\n",
    "    experiment = Experiment(ws, 'AML_Manual_PipelineTraining')\n",
    "else:\n",
    "    experiment = Experiment(ws, 'AML_AutoDevOps_PipelineTraining')\n",
    "run = experiment.submit(pipeline)\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "97fa612d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inital_model_version = 4\n",
      "final_model_version= 4\n",
      "{'runId': '59a54271-a226-47ea-9db8-db7c2faaa4e7', 'status': 'Completed', 'startTimeUtc': '2023-02-03T19:09:51.575347Z', 'endTimeUtc': '2023-02-03T19:13:38.62904Z', 'services': {}, 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{\"raw_file_location\":\"spam-data/spamformodel.csv\",\"model_name\":\"text_classification_001\",\"model_desc\":\"text_classification_001 description\",\"environment_name\":\"text-classificiation-env\",\"service_name\":\"text-classification\"}', 'azureml.continue_on_step_failure': 'False', 'azureml.continue_on_failed_optional_input': 'True', 'azureml.pipelineComponent': 'pipelinerun', 'azureml.pipelines.stages': '{\"Initialization\":null,\"Execution\":{\"StartTime\":\"2023-02-03T19:09:51.8840365+00:00\",\"EndTime\":\"2023-02-03T19:13:38.5485517+00:00\",\"Status\":\"Finished\"}}'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.59a54271-a226-47ea-9db8-db7c2faaa4e7/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=BZrIXRqX%2BmEUZ8m4CGAkEF0h0mwSrzTBjht7cBSwyKo%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-03T18%3A14%3A47Z&ske=2023-02-05T02%3A24%3A47Z&sks=b&skv=2019-07-07&st=2023-02-03T19%3A00%3A50Z&se=2023-02-04T03%3A10%3A50Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.59a54271-a226-47ea-9db8-db7c2faaa4e7/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=VNNYz%2BWMnZNKWCqwnn4hkky5zZDh2aa8mwYjlXw1VNc%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-03T18%3A14%3A47Z&ske=2023-02-05T02%3A24%3A47Z&sks=b&skv=2019-07-07&st=2023-02-03T19%3A00%3A50Z&se=2023-02-04T03%3A10%3A50Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://amldev5894561386.blob.core.windows.net/azureml/ExperimentRun/dcid.59a54271-a226-47ea-9db8-db7c2faaa4e7/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=V%2BK%2BUR5CBkPQ7bNpKIYcP7IlCvkNhNyyrBfa3DX41MA%3D&skoid=59787589-fb8c-44a5-ae3b-6f0d04ea6f21&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2023-02-03T18%3A14%3A47Z&ske=2023-02-05T02%3A24%3A47Z&sks=b&skv=2019-07-07&st=2023-02-03T19%3A00%3A50Z&se=2023-02-04T03%3A10%3A50Z&sp=r'}, 'submittedBy': 'e51aa7c8-2975-4062-85fe-af95c0b8e461'}\n",
      "59a54271-a226-47ea-9db8-db7c2faaa4e7\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "try:\n",
    "    final_model = Model(ws, model_name_to_register)\n",
    "    final_model_version = final_model.version\n",
    "except WebserviceException :\n",
    "    final_model_version = 0\n",
    "    \n",
    "print('inital_model_version = ' + str(inital_model_version))\n",
    "print('final_model_version= ' + str(final_model_version))\n",
    "\n",
    "status = run.get_status()\n",
    "run_details = run.get_details()\n",
    "\n",
    "print((run_details))\n",
    "print(run_details['runId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c5e98a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if final_model_version > 0 and (inital_model_version != final_model_version):\n",
    "    deploy = 'deploy'\n",
    "    model_details = {\n",
    "        \"name\" : final_model.name,\n",
    "        \"version\": final_model.version,\n",
    "        \"properties\": final_model.properties,\n",
    "        \"nextstep\": \"deploy\"\n",
    "    }\n",
    "    print(model_details)\n",
    "else:\n",
    "    deploy = 'no'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13d8198",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in final_model.properties:\n",
    "    print(x)\n",
    "    print(final_model.properties[x])\n",
    "\n",
    "print (final_model.properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95409c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "outputfolder = 'run_outputs'\n",
    "os.makedirs(outputfolder, exist_ok=True)\n",
    "\n",
    "if (final_model_version != inital_model_version):\n",
    "    print('new model registered')\n",
    "    with open(os.path.join(outputfolder, 'deploy_details.json'), \"w+\") as f:\n",
    "        f.write(str(model_details))\n",
    "    model_name = model_name_to_register\n",
    "    model_list = Model.list(ws, name=model_name_to_register, latest=True)\n",
    "    model_path = model_list[0].download(exist_ok=True)\n",
    "    model_file_name = model_name_to_register + '.pkl'\n",
    "    shutil.copyfile(model_file_name,  os.path.join(outputfolder,model_file_name))\n",
    "    \n",
    "    #create model.yml file.\n",
    "    with open(os.path.join(outputfolder, 'model.yml'), \"w+\") as f:\n",
    "        f.write('$schema: https://azuremlschemas.azureedge.net/latest/model.schema.json \\n')\n",
    "        f.write('name: ' + model_details['name'] + '\\n')\n",
    "        f.write('path: ' + model_name_to_register + '.pkl \\n')\n",
    "        f.write('description: Model created from local file. \\n')\n",
    "        if len(final_model.properties) > 0:\n",
    "            f.write('properties: ')\n",
    "            f.write(json.dumps(final_model.properties))\n",
    "            f.write('\\n')\n",
    "            f.write('tags: ')\n",
    "            f.write(json.dumps(final_model.properties))\n",
    "            \n",
    "    \n",
    "with open(os.path.join(outputfolder, 'run_details.json'), \"w+\") as f:\n",
    "    print(run_details)\n",
    "    f.write(str(run_details))\n",
    "\n",
    "with open(os.path.join(outputfolder, \"run_number.json\"), \"w+\") as f:\n",
    "    f.write(run_details['runId'])\n",
    "    \n",
    "with open(os.path.join(outputfolder, \"deploy.txt\"), \"w+\") as f:\n",
    "    f.write(deploy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170fd2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import PipelineEndpoint\n",
    "\n",
    "def published_pipeline_to_pipeline_endpoint(\n",
    "    workspace,\n",
    "    published_pipeline,\n",
    "    pipeline_endpoint_name,\n",
    "    pipeline_endpoint_description=\"Endpoint to Email Classification Training pipeline\",\n",
    "):\n",
    "    try:\n",
    "        pipeline_endpoint = PipelineEndpoint.get(\n",
    "            workspace=workspace, name=pipeline_endpoint_name\n",
    "        )\n",
    "        print(\"using existing PipelineEndpoint...\")\n",
    "        pipeline_endpoint.add_default(published_pipeline)\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        # create PipelineEndpoint if it doesn't exist\n",
    "        print(\"PipelineEndpoint does not exist, creating one for you...\")\n",
    "        pipeline_endpoint = PipelineEndpoint.publish(\n",
    "            workspace=workspace,\n",
    "            name=pipeline_endpoint_name,\n",
    "            pipeline=published_pipeline,\n",
    "            description=pipeline_endpoint_description\n",
    "        )\n",
    "\n",
    "if deploy == 'deploy':\n",
    "    print('deploy Email Classification Training Pipeline')\n",
    "    pipeline_endpoint_name = 'Email Classification Training Pipeline'\n",
    "    pipeline_endpoint_description = 'Endpoint to Email Classification Training pipeline'\n",
    "\n",
    "    published_pipeline = pipeline.publish(name=pipeline_endpoint_name,\n",
    "                                         description=pipeline_endpoint_description,\n",
    "                                         continue_on_step_failure=False)\n",
    "\n",
    "    published_pipeline_to_pipeline_endpoint(\n",
    "        workspace=ws,\n",
    "        published_pipeline=published_pipeline,\n",
    "        pipeline_endpoint_name=pipeline_endpoint_name,\n",
    "        pipeline_endpoint_description=pipeline_endpoint_description\n",
    "    )\n",
    "else:\n",
    "    print('do not publish pipeline')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ce62b9",
   "metadata": {},
   "source": [
    "## Testing out endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fee1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "import argparse\n",
    "from azureml.core import Run\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Get model from workspace - the code below will always retrieve the latest version of the model; specific versions can be targeted.\n",
    "model_list = Model.list(ws, name=model_name_to_register, latest=True)\n",
    "model_path = model_list[0].download(exist_ok=True)\n",
    "\n",
    "model = joblib.load(model_path)\n",
    "\n",
    "# inf_df = pd.read_csv('./spaminference.csv')\n",
    "\n",
    "# print(inferencing_data_df.shape)\n",
    "\n",
    "\n",
    "# X = inferencing_data_df['text']\n",
    "# # Make predictions with new dataframe\n",
    "# predictions = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c7ed5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1983e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd61565",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = Model.get_model_path('tester')\n",
    "model = joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69b596bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healthy\n",
      "http://e3a452fd-9556-4ad6-9082-1f1607b360eb.eastus2.azurecontainer.io/score\n",
      "{\"data\": [\"this is data\"]}\n",
      "[\"ham\"]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "from azureml.core.webservice import Webservice\n",
    "\n",
    "\n",
    "#get service endpoint\n",
    "service = Webservice(workspace=ws, name='text-classification')\n",
    "print(service.state)\n",
    "url = service.scoring_uri\n",
    "print(url)\n",
    "api_key = 'byZlLHt6dHdwUpva7vnxM7jUqGl7m85W'\n",
    "headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key)}\n",
    "\n",
    "\n",
    "\n",
    "def MakePrediction():\n",
    "    endpoint_url = url\n",
    "    x_new = ['this is data']\n",
    "    input_json = json.dumps({\"data\": x_new})\n",
    "    print(input_json)\n",
    "    body = input_json\n",
    "    r = requests.post(endpoint_url, headers=headers, data=body)\n",
    "    return (r.json())\n",
    "\n",
    "\n",
    "results = MakePrediction()\n",
    "print(results)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af03dcfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
